[
  {
    "objectID": "theory.html",
    "href": "theory.html",
    "title": "Theory",
    "section": "",
    "text": "Supply Chains and Scheduling\nThere are two ways to view the the Continuum Digital Twin1:\nThe first is best modelled by a scheduling approach. The second is principally a supply chain model.\nWe propose a hierarchical model for the CDT, composed of a Supply Chain Network Design2 coupled with a Resource Constrained Process Scheduling3. In such a hierarchical system, the supply chain model allocates jobs to the best facilities, and the scheduling model then (optimally) sequences jobs within a given facility. Supply chain optimization emphasizes “where” (facility location, data transfer mode, sourcing). Scheduling emphasizes “when” and “in what order.”\nLet us begin by defining supply chains and scheduling in the context of the CDT.\nThese two models are complementary:\nIn Figure 1 and Figure 2 below, we show two alternative viewpoints of a simple 4-job, 4-machine scheduling problem. The global mathematical formulation will effectively include and combine these two viewpoints, as depicted in Figure 3 and formulated below.",
    "crumbs": [
      "Theory"
    ]
  },
  {
    "objectID": "theory.html#supply-chains-and-scheduling",
    "href": "theory.html#supply-chains-and-scheduling",
    "title": "Theory",
    "section": "",
    "text": "Definition 1 (Supply Chain) A supply chain is a network (directed graph) of jobs, facilities, data storage, networks, processing and end-product delivery to users. The design poroblem is to optimally allocate an ordered list of data storage and data processing jobs to an optimal choice of storage and processing centres.\n\n\nDefinition 2 (Scheduling) Scheduling is a decision-making process that deals with the allocation of (limited) resources to tasks over given time periods. Its goal is to optimize one or more objectives. The resulting schedule is a job sequence determined for every machine (facility) of the processing system.\n\n\n\nthe SCND can be used for global, over a fixed period, modelling—for example over an entire project duration, or annualized;\nthe RCPSP can be used for time-dependent models, especially when uncertainty is introduced, as in a two-stage, or multi-stage, model—see below Section Uncertainty.\n\n\n\n\n\n\n\n\n\n\ngraph LR\n    A[0] --&gt;|\"$$c_{0,1}$$\"| B(\"$$J_1$$\")\n    B --&gt;|\"$$c_{1,2}$$\"| C(\"$$J_2$$\")\n    C --&gt;|\"$$c_{2,3}$$\"| D(\"$$J_3$$\")\n    C --&gt;|\"$$c_{2,4}$$\"| E(\"$$J_4$$\")\n    D --&gt;|\"$$c_{3,5}$$\"| F[5]\n    E --&gt;|\"$$c_{4,5}$$\"| F\n\n\n\n\n\n\n\n\n\nFigure 1: Job-centered view: A simple directed graph (DAG) for a genomics workflow with 4 processing jobs \\(J_1,\\cdots, J_4,\\) and data transfers \\(c_{i,j}\\) between them, including initial upload and final download. The tasks 0 and 5 are dummy tasks, representing the start and the end of the workflow.\n\n\n\n\n\n\n\n\n\n\n\nflowchart LR\n    A[(DC1)]:::otherclass --&gt; C{{HPC1}}:::thirdclass\n    B[(DC2)]:::otherclass \n    A --&gt; D{{HPC2}}:::thirdclass\n    %%A[(data1)]:::someclass --&gt; E{{HPC3}}:::thirdclass\n    C --&gt; F[(DC1)]:::otherclass\n    C --&gt; G[(DC2)]:::otherclass\n    F --&gt; H{{HPC1}}:::thirdclass\n    F --&gt; I{{HPC2}}:::thirdclass  \n    classDef someclass stroke:#f00\n    classDef otherclass stroke:#0f0\n    classDef thirdclass stroke:#00f\n\n\n\n\n\n\n\n\n\nFigure 2: Machine-centered view: Supply chain model for the CDT. For a given job, the dataset (stored in one of two Datacentres, \\(\\mathrm{DC}_1\\) or \\(\\mathrm{DC}_2\\)) can be processed on one of two HPC centres (\\(\\mathrm{HPC}_1\\) or \\(\\mathrm{HPC}_2\\)), and ouput data is sent to (and stored on) one of the two Datacentres, ready as input for the next job. This is repeated for each job in the ordered job list (DAG).\n\n\n\n\n\n\n\n\n\nFigure 3: The CDT model is based on RCPSP and SCND.",
    "crumbs": [
      "Theory"
    ]
  },
  {
    "objectID": "theory.html#supply-chain-network-design",
    "href": "theory.html#supply-chain-network-design",
    "title": "Theory",
    "section": "Supply Chain Network Design",
    "text": "Supply Chain Network Design\n\nProblem Definition\nLet \\(\\mathscr{J},\\) \\(\\mathscr{F},\\) and \\(\\mathscr{U}\\) be respective (finite) sets of jobs and datasets, HPC and datacentres (facilities), and end-users. The union \\[\\mathscr{N} \\doteq \\mathscr{J} \\cup \\mathscr{F} \\cup \\mathscr{U}\\] of these sets is viewed as the set of nodes of a directed graph \\((\\mathscr{N},\\mathscr{A}),\\) where \\(\\mathscr{A}\\) is a set of arcs (directed links) connecting these nodes in a way representing flow of the jobs—see Figure 1 and Figure 2. The processing facilities \\(\\mathscr{F}\\) can include HPC centres \\(\\mathscr{H},\\) data storage centres \\(\\mathscr{D},\\) and post-processing centres \\(\\mathscr{P},\\) i.e. \\(\\mathscr{F}=\\mathscr{H}\\cup\\mathscr{D}\\cup\\mathscr{P}.\\) Furthermore, HPC (\\(i\\in\\mathscr{H}\\)), data (\\(i\\in\\mathscr{D}\\)), and post-processing (\\(i\\in\\mathscr{P}\\)) centers can each be composed of sets of individual machines, \\(\\mathscr{M}_{i}\\) and the set \\(\\mathscr{F}\\) includes the processing centers as well as the machines in each center. Finally, let \\(\\mathscr{K}\\) be the set of jobs flowing through the ``supply chain,’’ the digital continuum in our case.\n\n\nState Variables\nThe state of the system, or supply chain, at a given time \\(t,\\) is represented by state variables and coefficients:\n\nthe available (open/used, or closed/unused) facilities:\n\ncompute centres \\(x^{C}_{i}\\in\\left\\{ 0,1\\right\\} ,\\) \\(i=1,\\ldots,N_{C}\\)\ndata centres \\(x^{D}_{j}\\in\\left\\{ 0,1\\right\\} ,\\) \\(j=1,\\ldots,N_{D}\\)\n\nthe quantity/number of jobs, or datasets, or volumes transferred\n\n\\(y_{ji}\\) from instrument (data centre) \\(j\\) to compute centre \\(i,\\)\n\\(y_{ij}\\) from compute centre \\(i\\) to data centre \\(j,\\)\n\\(y_{ik}\\) from compute centre \\(i\\) to user \\(k,\\)\n\\(y_{kj}\\) from user \\(k\\) to data centre \\(j,\\)\n\ncosts—both fixed and variable (eventually stochastic4)—are associated with each of the decision variables;\nresource supply/availability and demand/requests are specified for each facility, and eventually for each machine in a given facility—this can includes the ephemeral buffers (Garénaux-Gruau, Bodin, and Asch 2025).\n\n4 Either a discrete set or tabulated values drawn from a known probability distribution, or the PDF itself.\n\nObjective Function\nThe overall objective is to combine location decisions—which centres to use—with allocation decisions—how to distribute the workloads and jobs among the chosen centres (data and compute).\nThere can be a single objective such as minimizing (any function of) the total of fixed and variable costs, or minimizing the completion time (makespan). Multiple objective optimization5 seeks a tradeoff between minimum cost and maximum sustainability (minimum environmental impact). Finally, stochastic optimization takes into account the uncertainties of resource availabilities and delays, maintenance and failures, resource allocations, variable energy costs, project costs (HR, budget).\n5 MOOThe overall, deterministic cost function for total cost can be expressed as a sum (some terms can be ignored by setting the coefficients to zero, depending on the context) \\[\\begin{gather*}\n\\min_{x,y}\\sum^{N_{C}}_{i=1}f^{C}_{i}x^{C}_{i}+\\sum^{N_{D}}_{j=1}f^{D}_{j}x^{D}_{j}+\\sum^{N_{C}}_{i=1}\\sum^{N_{D}}_{j=1}c_{ji}y_{ji}+\\\\\n\\sum^{N_{D}}_{j=1}\\sum^{N_{C}}_{i=1}c_{ij}y_{ij}+\\sum^{N_{C}}_{i=1}\\sum^{N_{U}}_{k=1}c_{ik}y_{ik}+\\sum^{N_{U}}_{k=1}\\sum^{N_{D}}_{j=1}c_{kj}y_{kj}\n\\end{gather*}\\]\n\n\\(f^{C}_{i},\\) \\(f^{D}_{j}\\) are the fixed costs of using compute centre \\(i,\\) data centre \\(j;\\)\n\\(c_{ji},\\) \\(c_{ij},\\) \\(c_{ik},\\) \\(c_{kj}\\) are the variable costs of the job “flow” from data centre \\(j\\) to compute centre \\(i,\\) etc. along the arc \\((j,i)\\in\\mathscr{A}\\), etc.\n\\(y_{ji},\\) \\(y_{ij},\\) \\(y_{ik},\\) \\(y_{kj}\\) are the corresponding quantities “flowing” from data centre \\(j\\) to compute centre \\(i,\\) etc. along the arc \\((j,i)\\in\\mathscr{A}\\), etc.\n\\(x_{i},\\) \\(x_{j}\\) are binary variables, indicating the choice/use of a particular compute or data centre;\n\\(N_U\\) is the number of end-users;\nweights, or priorities, can be attributed to each term, to either balance the contributions, or to give greater importance to certain terms.\n\n NOTE: \n\n\nThis formulation can be considerably simplified by grouping all transfer costs, and summing over the union of facilities/machines available.\nRather express all this as a multi-mode RCPSP based on a DAG, as follows:\n\nThe resource-constrained project scheduling problem is a classical well-known problem in operations research. A number of activities are to be scheduled. Each activity has a duration and cannot be interrupted. There are a set of precedence relations between pairs of activities which state that the second activity must start after the first has finished. The set of precedence relations are usually given as a directed acyclic graph (DAG), where the edge \\((u,v)\\) represents a precedence relation where \\(u\\) must finish before \\(v\\) begins. The DAG contains two additional activities with duration 0, the source and sink, where the source is the first activity and sink is the last activity (these are dummy activities).\nThere are a set of renewable resources. Each resource has a maximum capacity and at any given time slot no more than this amount can be in use. Each activity has a demand (possibly zero) on each resource. The dummy source and sink activities have zero demand on all resources.\nThe problem is usually stated as an optimisation problem where the makespan (i.e. the completion time of the sink activity) is minimised.\nMulti-mode Variant An extension of the basic RCPSP is the multi-mode variant where activities may have multiple modes. The mode dictates the duration and resource demands of the activity. In this variant, the schedule must give the mode of each activity as well as its starting time.\nNon-Renewable Resources Another extension concerns non-renewable resources. Each non-renewable resource has a capacity for the entire schedule. An example would be a financial budget that applies to the entire project. Modes of activities must be chosen to avoid exceeding the capacity of each of the non-renewable resources. \n\n\nConfiguration Decisions\nWe suppose that supply chain configuration decisions consist of deciding which of the processing centers to engage, and eventually which processing and storage machines to use within each center.\n\n\nDynamic Networks\nWe can generalize the supply chain by considering a multi-stage network with an added time dimension. This enables flow and carrying of data and jobs across time periods, in addition to flow among facilities. For example, if certain facilites become unavailable, or less available, as the project evolves over time. This is a kind of recourse, which will be considered below in Section Uncertainty.\n\n\n\n\n\n\n\n\nflowchart LR\n    subgraph t1[\"t = 1\"]\n    direction LR\n    a1((\" \"))--&gt;a2((\" \"))\n    a1--&gt;a3((\" \"))\n    a2--&gt;a4((\" \"))\n    a2-.-&gt;a5((\" \"))\n    end\n    subgraph t2[\"t = 2\"]\n    direction LR\n    b1((\" \"))--&gt;b2((\" \"))\n    b1--&gt;b3((\" \"))\n    b2-.-&gt;b4((\" \"))\n    b2--&gt;b5((\" \"))\n    end\n    t1 --&gt; t2\n    style t1 fill: white\n    style t2 fill: white\n\n\n\n\n\n\n\n\nFigure 4: Multi-stage, dynamic network that evolves over time due to changing availability constraints.\n\n\n\n\n\nMathematical Formulation - Deterministic Model\nWe begin with a deterministic formulation, and then introduce uncertainties to obtain a full stochastic model.\nAssign a binary variable \\(x_{i}=1\\) if the processing facility \\(i\\) is engaged or machine \\(i\\) is used, and \\(x_{i}=0\\) otherwise. Operational decisions then consist of routing the flow of all the jobs \\(k\\in\\mathscr{K}\\) from the instrument—or primary data reposirory—to the end-user, in a cost-optimal way, still to be defined.\nLet \\(y^{k}_{ij}\\) denote the flow of job \\(k\\) from a node \\(i\\) to a node \\(j\\) of the network, where \\((i,j)\\in\\mathscr{A}\\) is an arc of the network. The flow will normally be a voluminous data transfer, possibly by even physically tansporting disk drives from remote locations.\nThe optimization problem—objective function and constraints—can be written as follows. It covers a very general case, with both optimal allocation and eventual resource constraints.\n\\[\\begin{align}\n\\min_{x,y} & \\sum_{i\\in\\mathscr{F}}c_{i}x_{i}+\\sum_{k\\in\\mathscr{K}}\\sum_{(i,j)\\in\\mathscr{A}}q^{k}_{ij}y^{k}_{ij} \\tag{1}\\label{eq:sc1}\\\\\n\\textrm{s.t.} & \\sum_{i\\in\\mathscr{N}}y^{k}_{ij}-\\sum_{\\ell\\in\\mathscr{N}}y^{k}_{j\\ell}=0,\\quad j\\in\\mathscr{F},\\;k\\in\\mathscr{K}, \\tag{2}\\label{eq:sc2}\\\\\n& \\sum_{i\\in\\mathscr{N}}y^{k}_{ij}\\ge d^{k}_{j},\\quad j\\in\\mathscr{U},\\;k\\in\\mathscr{K}, \\tag{3}\\label{eq:sc3}\\\\\n& \\sum_{i\\in\\mathscr{N}}y^{k}_{ij}\\le s^{k}_{j},\\quad j\\in\\mathscr{I},\\;k\\in\\mathscr{K}, \\tag{4}\\label{eq:sc4}\\\\\n& \\sum_{k\\in\\mathscr{K}}r^{k}_{j}\\sum_{i\\in\\mathscr{N}}y^{k}_{ij}\\le m_{j}x_{j},\\quad j\\in\\mathscr{F}, \\tag{5}\\label{eq:sc5}\\\\\n& x\\in\\mathscr{X},\\quad y\\ge0, \\tag{6}\\label{eq:sc6}\n\\end{align}\\]\n\nin \\(\\eqref{eq:sc1}\\), \\(c_{i}\\) is the cost of engaging facility \\(i\\) or using machine \\(i,\\) and \\(q^{k}_{ij}\\) is the per unit cost of processing job \\(k\\) at facility \\(i\\) and/or sending job \\(k\\) on arc \\((i,j)\\in\\mathscr{A},\\) (data transfer, transport and data storage costs)\nin \\(\\eqref{eq:sc3}\\), \\(d^{k}_{j}\\) is the “demand” of job \\(k\\) at node \\(j,\\) (eg. how many CPU’s or how much data storage capacity is required)\nin \\(\\eqref{eq:sc4}\\), \\(s^{k}_{j}\\) is the “supply” of job \\(k\\) at node \\(j,\\) (eg. how many CPU’s or how much data storage capacity is available)\nin \\(\\eqref{eq:sc5}\\), \\(r^{k}_{j}\\) is the per-unit processing requirement for job \\(k\\) at node \\(j,\\) and \\(m_{j}\\) is the capacity of facility \\(j,\\)\nin \\(\\eqref{eq:sc6}\\), \\(\\mathscr{X}\\subset\\left\\{ 0,1\\right\\} ^{\\left|\\mathscr{F}\\right|},\\) \\(y\\in\\mathbb{R}^{\\left|\\mathscr{A}\\right|\\times\\left|\\mathscr{K}\\right|}\\) is a vector with components \\(y^{k}_{ij},\\)\nall cost components are defined per given period (hour, day, week, month, etc.)\n\nThe above equations have the following interpretations.\n\nObjective function (\\(\\ref{eq:sc1}\\)) minimizes the total of investment6 plus operational7 costs.\n\\(\\mathscr{K}\\) represents logical dependencies and restrictions, such as \\(x_{i}\\le x_{j}\\) for all \\(i\\in\\mathscr{M}_{j},\\) where \\(j\\in\\left\\{ \\mathscr{H},\\mathscr{D},\\mathscr{P}\\right\\} ,\\) which means that machine \\(i\\) should be used only if facility \\(j\\) is engaged, and since the \\(x\\)’s are binary the constraint \\(x_{i}\\le x_{j}\\) implies that \\(x_{i}=0\\) if \\(x_{j}=0.\\)\nConstraints (\\(\\ref{eq:sc2}\\)) enforce the flow conservation of job \\(k\\) across each processing node \\(j.\\)\nConstraints (\\(\\ref{eq:sc3}\\)) require that the total flow of job \\(k\\) to a customer node \\(j\\) should exceed the “demand” \\(d^{k}_{j}\\) at that node.\nConstraints (\\(\\ref{eq:sc4}\\)) require that the total flow of job \\(k\\) from an instrument node \\(j\\) should be less than the “supply” \\(s^{k}_{j}\\) at that node.\nConstraints (\\(\\ref{eq:sc5}\\)) enforce capacity constraints of the processing nodes.\n\nRequire that the total processing requirement of all jobs flowing into a processing node \\(j\\) should be smaller than the capacity \\(m_{j}\\) of facility\\(j\\) if it is used (\\(x_{j}=1\\)).\nIf facility \\(j\\) is not used (\\(x_{j}=0\\)), the constraint will force all flow variables \\(y^{k}_{ij}=0\\) for all \\(i\\in\\mathscr{N}.\\)\n\nFinally, constraint (\\(\\ref{eq:sc6}\\)) enforces the feasibility constraint \\(x\\in\\mathscr{X}\\) and the non-negativity of the flow variables corresponding to an arc \\((i,j)\\in\\mathscr{A},\\) and job \\(k\\in\\mathscr{K}.\\)\n\n6 CAPEX7 OPEXWe can rewrite the above in a very compact, matrix-vector form.\n\\[\\begin{align*}\n\\min & \\,\\,c^{\\top}x+q^{\\top}y\\\\\n\\textrm{s.t.} & \\,\\,Ny=0,\\\\\n& Cy\\ge d,\\\\\n& Sy\\le s,\\\\\n& Ry\\le Mx,\n\\end{align*}\\] where\n\nvectors \\(c,\\) \\(q,\\) \\(d,\\) and \\(s\\) represent fixed costs, processing or transmission costs, demands, supplies, respectively;\nmatrices \\(N,\\) \\(C,\\) and \\(S\\) correspond to summations of the respective expressions, (nodes, demands, supplies);\n\\(R\\) is the matrix of \\(r^{k}_{j}\\) (requirements);\n\\(M=\\textrm{ diag }(m_{j})\\) (machine capacities).\n\n\n\nSimplified Cases\nThe above formulation covers both the cost-optimal streaming of jobs across the cyberinfrastructure as well as the respect of individual facilities’ constraints. The latter is a resource-constrained scheduling problem.\nUnconstrained-Resource Problem\nAs a first simplification, we suppose that the facilites possess the necessary capacities to service the requirements of all the incoming data storage and processing jobs. Suppose that we still have fixed and variable costs, so the objective does not change. The “infinite-resource” problem simplifies to:\n\\[\\begin{align}\n\\min_{x,y} & \\sum_{i\\in\\mathscr{F}}c_{i}x_{i}+\\sum_{k\\in\\mathscr{K}}\\sum_{(i,j)\\in\\mathscr{A}}q^{k}_{ij}y^{k}_{ij} \\tag{1a}\\label{eq:sc1a}\\\\\n\\textrm{s.t.} & \\sum_{i\\in\\mathscr{N}}y^{k}_{ij}-\\sum_{\\ell\\in\\mathscr{N}}y^{k}_{j\\ell}=0,\\quad j\\in\\mathscr{F},\\;k\\in\\mathscr{K}, \\tag{2a}\\label{eq:sc2a}\\\\        \n& x\\in\\mathscr{X},\\quad y\\ge0, \\tag{6a}\\label{eq:sc6a}\n\\end{align}\\]\nResource-Constrained Project Scheduling Problem (RCPSP)\nA second simplification is to consider the resource constraint problem, without facility or machine allocations. The Resource-Constrained Project Scheduling Problem (RCPSP) is a combinatorial optimization problem that consists of finding a feasible scheduling for a set of \\(n\\) jobs subject to resource and precedence constraints. Each job has a processing time, a set of successor jobs and a required amount of different resources. Resources may be scarce but are renewable at each time period. Precedence constraints between jobs mean that no jobs may start before all its predecessors are completed. The jobs must be scheduled non-preemptively, i.e., once started, their processing cannot be interrupted.\nThe RCPSP has the following input data:\n\n\\(\\mathcal{J}\\) set of jobs.\n\\(\\mathcal{R}\\) set of renewable resources.\n\\(\\mathcal{S}\\) set of precedences between jobs \\((i,j)\\in\\mathcal{J}\\times\\mathcal{J}.\\)\n\\(\\mathcal{T}\\) planning horizon: set of possible processing times for jobs.\n\\(p_{j}\\) processing time of job \\(j.\\)\n\\(u_{(j,r)}\\) amount of resource \\(r\\) required for processing job \\(j.\\)\n\\(c_{r}\\) capacity of renewable resource \\(r.\\)\n\nA binary programming formulation was proposed by Pritsker et al. in 1986. In this formulation, decision variables \\(x_{jt}=1\\) if job \\(j\\) is assigned to begin at time \\(t\\); otherwise, \\(x_{jt}=0.\\) All jobs must finish in a single period of time without violating precedence constraints while respecting the amount of available resources. The model proposed by Pristker can be stated as follows:\n\\[\n\\begin{alignedat}{1}\n\\textrm{Minimize} & \\sum_{t\\in\\mathcal{T}}t\\cdot x_{(n+1,t)}\\\\\n\\textrm{Subject to:} & \\sum_{t\\in\\mathcal{T}}x_{(j,t)}=1\\,\\,\\,\\forall j\\in J,\\\\\n& \\sum_{j\\in J}\\sum^{t}_{t_{2}=t-p_{j}+1}u_{(j,r)}x_{(j,t_{2})}\\leq c_{r}\\,\\,\\,\\forall t\\in\\mathcal{T},r\\in R,\\\\\n& \\sum_{t\\in\\mathcal{T}}t\\cdot x_{(s,t)}-\\sum_{t\\in\\mathcal{T}}t\\cdot x_{(j,t)}\\geq p_{j}\\,\\,\\,\\forall(j,s)\\in S,\\\\\n& x_{(j,t)}\\in\\{0,1\\}\\,\\,\\,\\forall j\\in J,t\\in\\mathcal{T}.\n\\end{alignedat}\n\\]\nMutli-Project Multi-Mode RCPSP\nNote that the above formulation is restricted to temporal scheduling on a single machine, and for a single project, or collection of jobs. This formulation has been generalized to deal with multiple machines and multiple projects. In this case, the formulation becomes very similar to that of a supply chain. It is referred to in the literature as the multi-mode resource-constrained multi-project scheduling problem, or MRCMPSP.\nMulti-Mode The single-mode RCPSP assumed that each activity has only one way to be executed, whereas the multi-mode RCPSP considers multiple ways to execute an activity, which often have tradeoffs in duration, cost, or resource requirement.\nMulti-Projec We can then perform simultaneous scheduling of a set of multiple projects taking into account the availability of local and global resources under different time and resource constraints. This has practical importance, at national and European levels, when cross-facility implies exploitation of cyberinfrastructure resources across different countries, for example, as would be the case for EuroHPC8, at the European level, or GENCI9 for France. Imagine being able to plan and pilot multiple exascale projects, on multiple sites, over multiple countries…10\n8  https://www.eurohpc-ju.europa.eu/ 9  https://www.genci.fr// 10 These would be multiple states, in the USA context.Resources The resources can be either renewable at each time period—HPC machines and data centers—or non-renewable, such is the case for the project budget.\nObjectives Various project performance metrics can be optimized, including task-based, resource-based, financial-based and user-based metrics. One can minimize makespan, tardiness, resource consumption, or maximize total NPV with respect to sustainability, for example.\nConclusion This general formulation of the RCPSP is then mathematically equivalent to the supply chain configuration problem11 with resource constraints. The loop is closed.\n11 SCCP",
    "crumbs": [
      "Theory"
    ]
  },
  {
    "objectID": "theory.html#optimization",
    "href": "theory.html#optimization",
    "title": "Theory",
    "section": "Optimization",
    "text": "Optimization\nIn summary, this book has no content whatsoever. In summary, this book has no content whatsoever.\n\nMILP formulations for RCPSP and SCND\nWe consider single- and multi-mode resource-constrained project scheduling problems. In summary, this book has no content whatsoever.\n\n\nPrecedence Constraints\nIn summary, this book has no content whatsoever. In summary, this book has no content whatsoever.\n\n\nDisjunctions\nIn summary, this book has no content whatsoever. In summary, this book has no content whatsoever.",
    "crumbs": [
      "Theory"
    ]
  },
  {
    "objectID": "theory.html#sec-stoch",
    "href": "theory.html#sec-stoch",
    "title": "Theory",
    "section": "Uncertainty",
    "text": "Uncertainty\nIn practice some of the scheduling parameters may be uncertain. The exact duration of an activity, for instance, might not be known at the beginning of the project. Similarly, the number of available resources is another parameter that may not be known before project execution. These uncertainties may be due to different sources, including estimation errors, unforeseen (weather) conditions, late “delivery” (unavailability) of some required resources, unpredictable incidents such as machine breakdown or worker accidents, etc.\n\n\n\n\nGarénaux-Gruau, Marius, François Bodin, and Mark Asch. 2025. “Continuum Digital Twin Implementation.” https://arxiv.org/abs/25xx.xxxx.",
    "crumbs": [
      "Theory"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "Introduction",
    "section": "",
    "text": "The Exa-AtoW Project\nA wide-scale, cross-facility workflow is a complex beast. It reunites users, jobs, and facilities, each with its resources and constraints. In the workflows that interest us, the facilites include data centres, HPC1 centres, and the network connections between these.\nThe basic problem can be resumed as follows: find an optimal schedule \\(S\\) for a collection of jobs \\(J\\) to be executed on a set of facilities \\(F,\\) subject to constraints on resources, availability, precedences. The optimization can be performed for various objectives, or combinations of these, such as cost, project duration, facility availability, environmental impact. The presence of uncertainty plays a central role and is included in the optimization process.\nExa-AToW focuses on effective end-to-end solutions, at scale, by considering not only functional dimensions such as workflows and data logistics but also resource federation governance, cybersecurity, energy, and sustainability.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "intro.html#the-exa-atow-project",
    "href": "intro.html#the-exa-atow-project",
    "title": "Introduction",
    "section": "",
    "text": "This work is part of the Exa-AtoW project, a member of the NumPEx consortium. The Exa-AToW project aims at providing solutions for the efficient management of large-scale workflows composed of HPDA, AI, and HPC tasks that are distributed over a continuum of resources ranging from the Exascale, HPC, and Data infrastructures.https://numpex.org",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "intro.html#continuum-digital-twin-or-shadow",
    "href": "intro.html#continuum-digital-twin-or-shadow",
    "title": "Introduction",
    "section": "Continuum Digital Twin or Shadow",
    "text": "Continuum Digital Twin or Shadow\nGiven the inherent complexity of Exascale workflows, they will inevitably be executed on a cross-facility infrastructure. Such a multi-component basis will inevtibaly be subject to uncertainties in availability, maintenance, cost, etc. In addition, the cybersecurity constraints will impose strict access conditions that make workflow testing basically impossible. And, more recently, the issue of sustainability and energy consumption by cyberinfrastructure (IEA 2025) is a critical issue, in particular for so-called hyperscalers and data centers used for AI training and inference.\nFor all these reasons, the presence of a digital twin, or shadow, is indispensable for testing and planning workflow executions before actually executing them. The computer science setup, based on micro-services and ontologies, is fully described in (Garénaux-Gruau, Bodin, and Asch 2025a) and extended use-cases are presented in (Garénaux-Gruau, Bodin, and Asch 2025b).\n\n\n\n\n\n\n\n\ngraph LR\n    A[SIM] --&gt; B[SCD]\n    B --&gt; C[OPT]\n    C --&gt; A\n\n\n\n\n\n\n\n\nFigure 1: Three modules of the CDT: simuulation (SIM), scheduling (SCD), optimization (OPT). An initial workflow definition enters at the left and an optimal workflow is produced.\n\n\n\nThe core of the CDT is a set of three modules: simulation, scheduling and optimization, as shown in Figure 1. They can be used independently, or be chained together. These three are fed by a shared database, based on a common ontology that contains descriptions of all the jobs to perform, resources available, constraints to be respected, and any objectives to be attained. This database is connected to, and communicates with the real world—see Figure 2. This communication can take the form of a MADPP (machine actionable data project plan), a user-interface, or a combination of the two (Garénaux-Gruau, Bodin, and Asch 2025a).\n\n\n\n\n\n\nFigure 2: Global software architecture of the CDT, consisting of three modules: simulation (SIM), scheduling (SCD), optimization (OPT).\n\n\n\nAll details can be found in (Garénaux-Gruau, Bodin, and Asch 2025c).",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "intro.html#uncertainty",
    "href": "intro.html#uncertainty",
    "title": "Introduction",
    "section": "Uncertainty",
    "text": "Uncertainty\nDeterministic schedules optimize for a world that, in theory, never materializes. Processing times vary, machines fail, networks are overloaded, demand shifts. As a result, a schedule that is “optimal” under perfect information often performs poorly when reality intervenes. Stochastic formulations, on the other hand, explicitly hedge against variability. The resulting schedules may sacrifice some of the theoretical efficiency, but maintain feasibility when disruptions occur, thus avoiding costly rescheduling or missed deadlines. Rather than a single makespan or cost figure, one can obtain distributions: “We meet the deadline with 95% confidence” which is far more informative than “the expected completion is Tuesday.”\nHence, when uncertainty in job durations or data transfer arrivals is modeled, the true value of buffer capacity, parallel facilities, or overtime flexibility becomes visible. Deterministic models systematically undervalue these. We can compute the value of the stochastic solution (VSS), which quantifies what can be gained by solving the full stochastic program rather than just optimizing against average conditions. Note that averaging yields a deterministic problem.\nThe Value of Stochastic Solution (VSS) is defined as the difference between the Expectation of the Expected Value Solution (EEVS) and the optimal objective value of the Recourse Problem (RP). The VSS quantifies the benefit of using a stochastic model in place of a deterministic one in decision-making problems under uncertainty. A large VSS signals that the system is sensitive to variability, hedging decisions matter, and the deterministic approximation is potentially dangerous.\n\n\n\\[\\mathrm{VSS} = \\mathrm{EEV} - \\mathrm{RP}\\]\nIn conclusion, when faced with expensive (financially and environmentally), time-consuming Exascale workflows, the need to consider uncertainty in the scheduling program is vital. Stochastic-based scheduling can take into account any uncertain resources and all uncertain costs—a good example would be variable energy costs. The solution thus obtained will permit a hedging strategy. We can, in addition, perform risk analysis, where we compare alternative deployments of the workflow as a function of our risk profile.\n\n\n\n\nGarénaux-Gruau, Marius, François Bodin, and Mark Asch. 2025a. “Continuum Digital Twin Implementation.” https://arxiv.org/abs/25xx.xxxx.\n\n\n———. 2025b. “Continuum Digital Twin Use Cases.” https://arxiv.org/abs/25xx.xxxx.\n\n\n———. 2025c. “Continuum Digital Twin—Mathematical Models.” https://arxiv.org/abs/25xx.xxxx.\n\n\nIEA, Paris. 2025. “Energy and AI.” https://www.iea.org/reports/energy-and-ai.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "examples.html",
    "href": "examples.html",
    "title": "Examples",
    "section": "",
    "text": "Examples\nIn summary, this book has no content whatsoever.\nIn summary, this book has no content whatsoever.\nimport matplotlib.pyplot as plt\nplt.plot([1,23,2,4])\nplt.show()\n\n\n\n\n\n\n\nFigure 1: A line plot\nWe observe in Figure 1 that there is a clear trend, up and down.",
    "crumbs": [
      "Examples"
    ]
  },
  {
    "objectID": "examples.html#use-cases",
    "href": "examples.html#use-cases",
    "title": "Examples",
    "section": "Use-Cases",
    "text": "Use-Cases\n\nSetup and Linear Programming Example\nAs an introduction we load the necessary pyomo packages and solve an ultra-simple linear programming example. \\[\n\\begin{array}{ll}\n  \\min       & 2 x_1 + 3 x_2\\\\\n  \\mathrm{s.t.} & 3 x_1 + 4 x_2 \\geq 1\\\\\n             & x_1, x_2 \\geq 0\n\\end{array}\n\\]\n\npyomo.environ provides the framework for building the model\nSolverFactory allows to call the solver used to solve the optimization problem\n\n\nimport pyomo.environ as pyo \nfrom pyomo.opt import SolverFactory \n\nimport pyomo.environ as pyo\n\nmodel = pyo.ConcreteModel(\"Simple Linear\")\n# Decision variables and domains\nmodel.x = pyo.Var([1,2], domain=pyo.NonNegativeReals)\n# Objective function\nmodel.OBJ = pyo.Objective(expr = 2*model.x[1] + 3*model.x[2])\n# Constraint(s)\nmodel.Constraint1 = pyo.Constraint(expr = 3*model.x[1] + 4*model.x[2] &gt;= 1)\n\nsolver = 'appsi_highs'\nSOLVER = pyo.SolverFactory(solver)\nassert SOLVER.available(), f\"Solver {solver} is not available.\"\n\n# Solve and print solution\nSOLVER.solve(model)\nprint(f\"x = ({pyo.value(model.x[1]):.2f}, {pyo.value(model.x[2]):.2f})\")\nprint(f\"optimal value = {pyo.value(model.OBJ):.2f}\")\n\nx = (0.33, 0.00)\noptimal value = 0.67\n\n\nWe can print out\n\nthe complete model;\na full trace of the optimization process.\n\n(use collapsed display here - click to expand and view output)\n\n\nPrecedence Example\nWe illustrate how to set up a precedence table, made up of job pairs that define pairwise precedences.\n\n\nDisjunctions\nWhen faced with a choice among exclusive options, we resort to disjunctive programming, based on:\n\nBig-M formulation.\nLogical formulation.\n\n\n\nSimplified Supply Chain Example\nPutting together:\n\nprecedence\nTBC\n\n\n\nSimplified RCPSP Example\nPutting together:\n\nprecedence\nTBC",
    "crumbs": [
      "Examples"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Optimal Scheduling for Cross-Facility Workflows",
    "section": "",
    "text": "Welcome\nThis (online) book-document contains a complete presentation of optimal scheduling applied to Exascale and post-Exascale workflows. These workflows combine data acquisition, data storage, data transfer and data analysis. The HPC components of such workflows can incorporate a diverse range of models, including partial differential equation solvers, algebraic solvers, AI/ML-based models, and data analytics components, all integrated into a single process (Ferreira da Silva et al. 2024), (Unat et al. 2025).\nThe objective here is to address the inherent cross-facility, multi-domain character of these workflows. This requires a very carefully-crafted theoretical foundation that can be readily generalized and extended to these contexts. The material covers both the theory and its application to practical use-cases, including real contexts with uncertainties emanating from different causes. To understand these well, numerous examples are provided in the form of python code snippets and jupyter notebooks. All of these are intgerated in a digital twin1 of the underlying cyberinfrastructure, the so-called digital continuum.\nThe Continuum Digital Twin (CDT) is defined and described in the series of forthcoming papers (Garénaux-Gruau, Bodin, and Asch 2025a, 2025b, 2025c). For optimization and scheduling, there are numerous excellent references. Among these we point out particularly (Birge and Louveaux 2011), (Pinedo 2022), and (Powell 2022). Most of the codes are based on the wonderful pyomo framework (Bynum et al. 2021), (Hart, Watson, and Woodruff 2011) and (Postek et al. 2025). General background on exascale workflows can be found in (M. Asch et al. 2018).",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#author",
    "href": "index.html#author",
    "title": "Optimal Scheduling for Cross-Facility Workflows",
    "section": "Author",
    "text": "Author\nMark Asch is Emeritus Professor of the Université de Picardie Jules Verne, Mathematics department.\nhttps://markasch.github.io/DT-tbx-v1/\nhttps://github.com/markasch/\nhttp://masch.perso.math.cnrs.fr/\nmark.asch@u-picardie.fr",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#citation",
    "href": "index.html#citation",
    "title": "Optimal Scheduling for Cross-Facility Workflows",
    "section": "Citation",
    "text": "Citation\nAsch, Mark. Optimal Scheduling for Cross-Facility Workflows. Online (2026) https://markasch.github.io/RCPSP4CDT/\n@book{Asch2026\n    title = {Optimal {S}cheduling for {C}ross-{F}acility {W}orkflows},\n    author = {Asch, Mark},\n    url = {https://markasch.github.io/RCPSP4CDT/},\n    year = {2026},\n    publisher = {Online}\n}",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#license",
    "href": "index.html#license",
    "title": "Optimal Scheduling for Cross-Facility Workflows",
    "section": "License",
    "text": "License\nThis online book is frequently updated and edited. It’s content is free to use, licensed under a Creative Commons licence, and the code can be found on GitHub. A physical copy of the book will be available at a later date.\nLicense: Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#references",
    "href": "index.html#references",
    "title": "Optimal Scheduling for Cross-Facility Workflows",
    "section": "References",
    "text": "References\n\n\nAsch, Mark. 2022. A Toolbox for Digital\nTwins: From\nModel-Based to\nData-Driven. Philadelphia, PA: Society\nfor Industrial; Applied Mathematics. https://doi.org/10.1137/1.9781611976977.\n\n\nAsch, M, T Moore, R Badia, M Beck, P Beckman, T Bidot, F Bodin, et al.\n2018. “Big Data and Extreme-Scale Computing: Pathways to\nConvergence-Toward a Shaping Strategy for a Future Software and Data\nEcosystem for Scientific Inquiry.” The International Journal\nof High Performance Computing Applications 32 (4): 435–79. https://doi.org/10.1177/1094342018778123.\n\n\nBirge, John R., and François Louveaux. 2011. Introduction to\nStochastic Programming. Second edition. Springer New\nYork, NY. https://doi.org/10.1007/978-1-4614-0237-4.\n\n\nBynum, Michael L., Gabriel A. Hackebeil, William E. Hart, Carl D. Laird,\nBethany L. Nicholson, John D. Siirola, Jean-Paul Watson, and David L.\nWoodruff. 2021. Pyomo–Optimization Modeling in Python. Third.\nVol. 67. Springer Science & Business Media.\n\n\nFerreira da Silva, Rafael, Rosa M. Badia, Deborah Bard, Ian T. Foster,\nShantenu Jha, and Frederic Suter. 2024.“Frontiers in Scientific Workflows: Pervasive Integration\nWith High-Performance Computing .” Computer 57\n(08): 36–44. https://doi.org/10.1109/MC.2024.3401542.\n\n\nGarénaux-Gruau, Marius, François Bodin, and Mark Asch. 2025a.\n“Continuum Digital Twin Implementation.” https://arxiv.org/abs/25xx.xxxx.\n\n\n———. 2025b. “Continuum Digital Twin Use Cases.” https://arxiv.org/abs/25xx.xxxx.\n\n\n———. 2025c. “Continuum Digital Twin—Mathematical Models.”\nhttps://arxiv.org/abs/25xx.xxxx.\n\n\nHart, William E, Jean-Paul Watson, and David L Woodruff. 2011.\n“Pyomo: Modeling and Solving Mathematical Programs in\nPython.” Mathematical Programming Computation 3 (3):\n219–60.\n\n\nIEA, Paris. 2025. “Energy and AI.” https://www.iea.org/reports/energy-and-ai.\n\n\nPinedo, Michael L. 2022. Scheduling: Theory, Algorithms, and\nSystems. 6th edition. Springer Cham.\n\n\nPostek, Krzysztof, Alessandro Zocca, Joaquim Gromicho, and Jeffrey\nKantor. 2025. Hands-On Mathematical\nOptimization with Python. Cambridge University Press. https://doi.org/10.1017/9781009493512.\n\n\nPowell, Warren B. 2022. Reinforcement Learning and Stochastic\nOptimization: A Unified Framework for Sequential Decisions. John\nWiley & Sons.\n\n\nUnat, Didem, Anshu Dubey, Emmanuel Jeannot, and John Shalf. 2025.\n“The Persistent Challenge of Data Locality in the Post-Exascale\nEra.” Computing in Science & Engineering 27 (4):\n19–27. https://doi.org/10.1109/MCSE.2025.3567586.",
    "crumbs": [
      "Welcome"
    ]
  }
]