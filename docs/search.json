[
  {
    "objectID": "examples.html",
    "href": "examples.html",
    "title": "Implementation",
    "section": "",
    "text": "Basic pyomo Linear Programming Example\nThis section details all the practical aspects of the optimal CDT scheduling. We intentionally provide a very general framework, but illustrate it with several simple examples.\nAs an introduction we load the necessary pyomo packages and solve an ultra-simple linear programming example. \\[\n\\begin{array}{ll}\n  \\min       & 2 x_1 + 3 x_2\\\\\n  \\mathrm{s.t.} & 3 x_1 + 4 x_2 \\geq 1\\\\\n             & x_1, x_2 \\geq 0\n\\end{array}\n\\]\nimport pyomo.environ as pyo \nfrom pyomo.opt import SolverFactory \n\nmodel = pyo.ConcreteModel(\"Simple Linear\")\n# Decision variables and domains\nmodel.x = pyo.Var([1,2], domain=pyo.NonNegativeReals)\n# Objective function\nmodel.OBJ = pyo.Objective(expr = 2*model.x[1] + 3*model.x[2])\n# Constraint(s)\nmodel.Constraint1 = pyo.Constraint(expr = 3*model.x[1] + 4*model.x[2] &gt;= 1)\n\nsolver = 'appsi_highs'\nSOLVER = pyo.SolverFactory(solver)\nassert SOLVER.available(), f\"Solver {solver} is not available.\"\n\n# Solve and print solution\nSOLVER.solve(model)\nprint(f\"x = ({pyo.value(model.x[1]):.2f}, {pyo.value(model.x[2]):.2f})\")\nprint(f\"optimal value = {pyo.value(model.OBJ):.2f}\")\n\nx = (0.33, 0.00)\noptimal value = 0.67\nWe can print out",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Implementation</span>"
    ]
  },
  {
    "objectID": "examples.html#cdt-implementation",
    "href": "examples.html#cdt-implementation",
    "title": "Implementation",
    "section": "CDT Implementation",
    "text": "CDT Implementation\nBefore addressing the simple examples of resource scheduling and the use cases, we describe the overall implementation, as shown in Figure 1.1.\n\n\n\n\n\n\n\n\nflowchart LR\n    A[/Input/] --&gt; B[\"Model \n                      Function\"]\n    B --&gt; C[\"pyomo\n             Model\"] \n    C --&gt; D[/Schedule /]\n\n\n\n\n\n\n\n\nFigure 1.1: The implementation in 4 stages.\n\n\n\n\nInput description of jobs (json file), that is loaded into …\nModel function, that generates …\npyomo model, which produces …\nOutput, an optimal schedule (csv file).\n\n\nInput File\nThis json file1 contains a complete description of the CDT that we want to model for optimization. Thanks to its genericity, it can be readily adapted to a wide diversity of projects, and even to global job scheduling on national or European levels.\n1 The actual file format is illustrated below in the examples.The input file contains all the information regarding the following characteristics of the CDT:\n\n\\(\\mathcal{P} = \\{P_1, P_2, \\ldots \\}\\) the list of projects;\n\\(\\mathcal{J}_i = \\{J_1^i, J_2^i, \\ldots \\}\\) the list of jobs per project2;\n\\(\\mathcal{O}_j = \\{O_1^j, O_2^j, \\ldots \\}\\) the list of operations per job3;\n\\(\\mathcal{M}_k = \\{M_1^k, M_2^k, \\ldots \\}\\) the list of modes per job (operation)4;\nResources:\n\n\\(\\mathcal{R}_l^{\\rho} = \\{R_1^l, R_2^l, \\ldots \\}\\) list of renewable resources per mode;\n\\(\\mathcal{R}_l^{\\nu} = \\{R_1^l, R_2^l, \\ldots \\}\\) list of non-renewable resources per project;\n\nJob requirements per resource: \\(p_{ij}\\)\nCosts per resource: \\(c_{ij}\\)\nList of precedences5: \\(\\mathcal{E} = \\{(i,j) \\mid i \\prec j, \\, i,j \\in \\mathcal{J} \\}.\\)\n\n2 These are of type data transfer, data storage, data processing, etc.3 This is an optional sub-group–the operations can just be considered as additional jobs.4 These are the facilities that can be exploited for each category of job: networks, data centers, HPC centers, etc.5 Successors, predecessors, as defined by the workflow DAG",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Implementation</span>"
    ]
  },
  {
    "objectID": "examples.html#simplified-supply-chain-example",
    "href": "examples.html#simplified-supply-chain-example",
    "title": "Implementation",
    "section": "Simplified Supply Chain Example",
    "text": "Simplified Supply Chain Example\nPutting together:\n\nprecedence\nTBC",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Implementation</span>"
    ]
  },
  {
    "objectID": "examples.html#simplified-rcpsp-example",
    "href": "examples.html#simplified-rcpsp-example",
    "title": "Implementation",
    "section": "Simplified RCPSP Example",
    "text": "Simplified RCPSP Example\nPutting together:\n\nprecedence\ntime-indexed\ndisjunctive",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Implementation</span>"
    ]
  },
  {
    "objectID": "examples.html#simplified-mrcpsp-example",
    "href": "examples.html#simplified-mrcpsp-example",
    "title": "Implementation",
    "section": "Simplified MRCPSP Example",
    "text": "Simplified MRCPSP Example\nIn this example we have 4 jobs, 2 possible modes, 1 renewable resource and no non-renewable resources. Jobs 2 and 3 can be executed in mode 1 or in mode 2.\n\n\n\n\n\n\n\n\ngraph LR\n    A[\"$$J_0$$\"] --&gt; B(\"$$J_1$$\")\n    A --&gt; C(\"$$J_2$$\")\n    B --&gt; D(\"$$J_3$$\")\n    C --&gt; E(\"$$J_4$$\")\n    D --&gt; F[\"$$J_5$$\"]\n    E --&gt; F\n\n\n\n\n\n\n\n\n\nFigure 1.2: A project network represented as a directed acyclic graph (DAG) for a workflow with 4 processing jobs \\(J_1,\\cdots, J_4.\\) The tasks 0 and 5 are dummy tasks, representing the start and the end of the workflow.\n\n\n\nThe project instance, shown above, is detailed in Table 1, where \\(S_j\\) is the successor list of job \\(j,\\) \\(m\\) is the mode, \\(d_{jm}\\) is the job duration, \\(k^{\\rho}_{jm1}\\) is the renewable resource requirement, \\(R^{\\rho}\\) is the renewable resource list, \\(K^{\\rho}\\) is the renewable resource limit, and \\(R^{\\nu}\\) is the non-renewable resource list, taken as empty. In other words we have 4 jobs, 2 possible modes, 1 renewable resource and no non-renewable resources. Jobs 2 and 3 can be executed in mode 1 or in mode 2.\n\\[\\begin{aligned}\n& \\text {Table 1. Multi-mode RCPSP for a 4-job, 2-mode workflow. }\\\\\n&\\begin{array}{cccccccc}\n%\\begin{tabular}{|c|c|c|c|c|c|c|c|}\n\\hline\nj & S_{j}& m & d_{jm} & k^{\\rho}_{jm1} & R^{\\rho} & K^{\\rho}_{1} & R^{\\nu}\\\\\n\\hline\n0 & \\left\\{ 1,2\\right\\}  & 1 & 0 & 0 & \\left\\{ 1\\right\\}  & 3 & \\emptyset \\\\\n1 & \\left\\{ 3\\right\\}  & 1 & 2 & 2  &  &  & \\\\\n2 & \\left\\{ 4\\right\\}  & 1 & 2 & 2 &  &  & \\\\\n&  & 2 & 3 & 1 &  &  & \\\\\n3 & \\left\\{ 5\\right\\}  & 1 & 1 & 3 &  &  & \\\\\n&  & 2 & 2 & 1 &  &  & \\\\\n4 & \\left\\{ 5\\right\\}  & 1 & 2 & 3 &  &  & \\\\\n5 & \\emptyset & 1 & 0 & 0 &  &  & \\\\\n\\hline\n%\\end{tabular}\n\\end{array}\n\\end{aligned}\\]\nInput File\nThe input file is a direct transcription of the table of variables.\n{\n  \"0\":{\"suc\":(\"1\",\"2\"),\"mod\":\"A\",\"drt\":0,    \"rsc\":0},\n  \"1\":{\"suc\":\"3\",\"mod\":\"A\",      \"drt\":2,    \"rsc\":2},\n  \"2\":{\"suc\":\"4\",\"mod\":(\"A\",\"B\"),\"drt\":[2,3],\"rsc\":[2, 1]},\n  \"3\":{\"suc\":\"5\",\"mod\":(\"A\",\"B\"),\"drt\":[1,2],\"rsc\":[3, 1]},\n  \"4\":{\"suc\":\"5\",\"mod\":\"A\",      \"drt\":2,    \"rsc\":3},\n  \"5\": {\"suc\":\"\",\"mod\":\"A\",      \"drt\":0,    \"rsc\":0 }\n}\nimport json\n\nwith open(\"input.json\", \"r\") as jsonfile: \n    TASKS = json.load(jsonfile)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Implementation</span>"
    ]
  },
  {
    "objectID": "examples.html#use-cases",
    "href": "examples.html#use-cases",
    "title": "Implementation",
    "section": "Use-Cases",
    "text": "Use-Cases\n\nDDFACET\nTBC\nTBC\nTBC\n\n\nNSBAS\nTBC\nTBC\nTBC",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Implementation</span>"
    ]
  },
  {
    "objectID": "examples.html#silly-examples",
    "href": "examples.html#silly-examples",
    "title": "Implementation",
    "section": "Silly Examples",
    "text": "Silly Examples\nIn summary, this book has no content whatsoever.\n\nimport matplotlib.pyplot as plt\nplt.plot([1,23,2,4])\nplt.show()\n\n\n\n\n\n\n\nFigure 1.3: A line plot\n\n\n\n\n\nWe observe in Figure 1.3 that there is a clear trend, up and down.\nTo only have code displayed, but not executed…\n#| label: fig-line-plot\n#| fig-cap: \"A line plot \"\n\nimport matplotlib.pyplot as plt\nplt.plot([1,23,2,4])\nplt.show()",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Implementation</span>"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "Introduction",
    "section": "",
    "text": "The Exa-AtoW Project\nA wide-scale, cross-facility workflow is a complex beast. It reunites users, jobs, and facilities, each with its resources and constraints. In the workflows that interest us, the facilites include data centres, HPC1 centres, and the network connections between these.\nThe basic problem can be resumed as follows: find an optimal schedule \\(S\\) for a collection of jobs \\(J\\) to be executed on a set of facilities \\(F,\\) subject to constraints on resources, availability, precedences. The optimization can be performed for various objectives, or combinations of these, such as cost, project duration, facility availability, environmental impact. The presence of uncertainty plays a central role and is included in the optimization process.\nExa-AToW focuses on effective end-to-end solutions, at scale, by considering not only functional dimensions such as workflows and data logistics but also resource federation governance, cybersecurity, energy, and sustainability.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "intro.html#the-exa-atow-project",
    "href": "intro.html#the-exa-atow-project",
    "title": "Introduction",
    "section": "",
    "text": "This work is part of the Exa-AtoW project, a member of the NumPEx consortium. The Exa-AToW project aims at providing solutions for the efficient management of large-scale workflows composed of HPDA, AI, and HPC tasks that are distributed over a continuum of resources ranging from the Exascale, HPC, and Data infrastructures.https://numpex.org",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "intro.html#continuum-digital-twin-or-shadow",
    "href": "intro.html#continuum-digital-twin-or-shadow",
    "title": "Introduction",
    "section": "Continuum Digital Twin or Shadow",
    "text": "Continuum Digital Twin or Shadow\nGiven the inherent complexity of Exascale workflows, they will inevitably be executed on a cross-facility infrastructure. Such a multi-component basis will inevtibaly be subject to uncertainties in availability, maintenance, cost, etc. In addition, the cybersecurity constraints will impose strict access conditions that make workflow testing basically impossible. And, more recently, the issue of sustainability and energy consumption by cyberinfrastructure (IEA 2025) is a critical issue, in particular for so-called hyperscalers and data centers used for AI training and inference.\nFor all these reasons, the presence of a digital twin, or shadow, is indispensable for testing and planning workflow executions before actually executing them. The computer science setup, based on micro-services and ontologies, is fully described in (Garénaux-Gruau, Bodin, and Asch 2025a) and extended use-cases are presented in (Garénaux-Gruau, Bodin, and Asch 2025b).\n\n\n\n\n\n\n\n\ngraph LR\n    A[SIM] --&gt; B[SCD]\n    B --&gt; C[OPT]\n    C --&gt; A\n\n\n\n\n\n\n\n\nFigure 1: Three modules of the CDT: simuulation (SIM), scheduling (SCD), optimization (OPT). An initial workflow definition enters at the left and an optimal workflow is produced.\n\n\n\nThe core of the CDT is a set of three modules: simulation, scheduling and optimization, as shown in Figure 1. They can be used independently, or be chained together. These three are fed by a shared database, based on a common ontology that contains descriptions of all the jobs to perform, resources available, constraints to be respected, and any objectives to be attained. This database is connected to, and communicates with the real world—see Figure 2. This communication can take the form of a MADPP (machine actionable data project plan), a user-interface, or a combination of the two (Garénaux-Gruau, Bodin, and Asch 2025a).\n\n\n\n\n\n\nFigure 2: Global software architecture of the CDT, consisting of three modules: simulation (SIM), scheduling (SCD), optimization (OPT).\n\n\n\nAll details can be found in (Garénaux-Gruau, Bodin, and Asch 2025c).",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "intro.html#uncertainty",
    "href": "intro.html#uncertainty",
    "title": "Introduction",
    "section": "Uncertainty",
    "text": "Uncertainty\nDeterministic schedules optimize for a world that, in theory, never materializes. Processing times vary, machines fail, networks are overloaded, demand shifts. As a result, a schedule that is “optimal” under perfect information often performs poorly when reality intervenes. Stochastic formulations, on the other hand, explicitly hedge against variability. The resulting schedules may sacrifice some of the theoretical efficiency, but maintain feasibility when disruptions occur, thus avoiding costly rescheduling or missed deadlines. Rather than a single makespan or cost figure, one can obtain distributions: “We meet the deadline with 95% confidence” which is far more informative than “the expected completion is Tuesday.”\nHence, when uncertainty in job durations or data transfer arrivals is modeled, the true value of buffer capacity, parallel facilities, or overtime flexibility becomes visible. Deterministic models systematically undervalue these. We can compute the value of the stochastic solution (VSS), which quantifies what can be gained by solving the full stochastic program rather than just optimizing against average conditions. Note that averaging yields a deterministic problem.\nThe Value of Stochastic Solution (VSS) is defined as the difference between the Expectation of the Expected Value Solution (EEVS) and the optimal objective value of the Recourse Problem (RP). The VSS quantifies the benefit of using a stochastic model in place of a deterministic one in decision-making problems under uncertainty. A large VSS signals that the system is sensitive to variability, hedging decisions matter, and the deterministic approximation is potentially dangerous.\n\n\n\\[\\mathrm{VSS} = \\mathrm{EEV} - \\mathrm{RP}\\]\nIn conclusion, when faced with expensive (financially and environmentally), time-consuming Exascale workflows, the need to consider uncertainty in the scheduling program is vital. Stochastic-based scheduling can take into account any uncertain resources and all uncertain costs—a good example would be variable energy costs. The solution thus obtained will permit a hedging strategy. We can, in addition, perform risk analysis, where we compare alternative deployments of the workflow as a function of our risk profile.\n\n\n\n\nGarénaux-Gruau, Marius, François Bodin, and Mark Asch. 2025a. “Continuum Digital Twin Implementation.” https://arxiv.org/abs/25xx.xxxx.\n\n\n———. 2025b. “Continuum Digital Twin Use Cases.” https://arxiv.org/abs/25xx.xxxx.\n\n\n———. 2025c. “Continuum Digital Twin—Mathematical Models.” https://arxiv.org/abs/25xx.xxxx.\n\n\nIEA, Paris. 2025. “Energy and AI.” https://www.iea.org/reports/energy-and-ai.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "theory.html",
    "href": "theory.html",
    "title": "Theory",
    "section": "",
    "text": "Some History…\nThe development of a framework for CDT process scheduling is rooted in the job scheduling problems that emerged with industrialization and assembly-line work. It is not a coincidence that many of the classical scheduling problems have names like Job Shop Problem or Flow Shop Problem. Back then and now the targets are the same: execute complex jobs that might need treatment on different machines in a defined sequential orders with certain degrees of efficiency. Efficiency in this context can be defined in a number of ways. It might be the total time needed to execute a set of jobs, the compliance of given deadlines, the minimization of overall costs or a combination of all the above.\nThere are two ways to view the the Continuum Digital Twin1:\nThe first is best modelled by a supply chain model. The second is principally a scheduling approach.\nWe propose a combined model for the CDT, composed of a Supply Chain Network Design2 coupled with a Resource Constrained Process Scheduling3. In such a hierarchical system, the supply chain model allocates jobs to the best facilities, and the scheduling model then (optimally) sequences jobs among facilities and within a given facility. Supply chain optimization emphasizes “where” (facility choice, data transfer mode). Scheduling emphasizes “when” and “in what order.”",
    "crumbs": [
      "Theory"
    ]
  },
  {
    "objectID": "theory.html#some-history",
    "href": "theory.html#some-history",
    "title": "Theory",
    "section": "",
    "text": "1 CDT\nFacility- or Machine-centered view.\nJob-centered view.\n\n\n\n\n\n\n\n\nFigure 1: Two different viewponts of the CDT: a supply chain model (left) and a scheduling model (right). DC = data center, CC = compute center, J = job.\n\n\n\n\n2 SCND3 RCPSPRecall the basic problem: given a directed graph of \\(N\\) data storage, transfer and processing jobs \\(\\mathscr{J},\\) find an optimal allocation \\(A\\) and a feasible schedule \\(S.\\) Further details below.\\(\\mathscr{J}=\\{ J_1, J_2, \\ldots J_N\\},\\)",
    "crumbs": [
      "Theory"
    ]
  },
  {
    "objectID": "theory.html#supply-chains-with-scheduling",
    "href": "theory.html#supply-chains-with-scheduling",
    "title": "Theory",
    "section": "Supply Chains with Scheduling",
    "text": "Supply Chains with Scheduling\nLet us begin by defining supply chains and scheduling in the context of the CDT.\n\nDefinition 1 (Supply Chain) A supply chain is a network (directed graph) of jobs, facilities, data storage, networks, processing and end-product delivery to users. The design poroblem is to optimally allocate an ordered list of data storage and data processing jobs to an optimal choice of storage and processing centres.\n\n\nDefinition 2 (Scheduling) Scheduling is a decision-making process that deals with the allocation of (limited) resources to tasks over given time periods. Its goal is to optimize one or more objectives. The resulting schedule is a job sequence determined for every machine (facility) of the processing system.\n\nThese two models are complementary:\n\nthe SCND can be used for global, over a fixed period, modelling—for example over an entire project duration, or annualized;\nthe RCPSP can be used for time-dependent models, especially when uncertainty is introduced, as in a two-stage, or multi-stage, model—see below Section Uncertainty.\n\nIn Figure 2 and Figure 3 below, we show the two alternative viewpoints of a simple 4-job, 4-machine scheduling problem. The global mathematical formulation will effectively include and combine these two viewpoints, as depicted in Figure 4 and formulated below.\n\n\n\n\n\n\n\n\ngraph LR\n    A[0] --&gt;|\"$$c_{0,1}$$\"| B(\"$$J_1$$\")\n    B --&gt;|\"$$c_{1,2}$$\"| C(\"$$J_2$$\")\n    C --&gt;|\"$$c_{2,3}$$\"| D(\"$$J_3$$\")\n    C --&gt;|\"$$c_{2,4}$$\"| E(\"$$J_4$$\")\n    D --&gt;|\"$$c_{3,5}$$\"| F[5]\n    E --&gt;|\"$$c_{4,5}$$\"| F\n\n\n\n\n\n\n\n\n\nFigure 2: Job-centered view: A simple directed graph (DAG) for a genomics workflow with 4 processing jobs \\(J_1,\\cdots, J_4,\\) and data transfers \\(c_{i,j}\\) between them, including initial upload and final download. The tasks 0 and 5 are dummy tasks, representing the start and the end of the workflow.\n\n\n\n\n\n\n\n\n\n\n\nflowchart LR\n    A[(DC1)]:::otherclass --&gt; C{{HPC1}}:::thirdclass\n    B[(DC2)]:::otherclass \n    A --&gt; D{{HPC2}}:::thirdclass\n    %%A[(data1)]:::someclass --&gt; E{{HPC3}}:::thirdclass\n    C --&gt; F[(DC1)]:::otherclass\n    C --&gt; G[(DC2)]:::otherclass\n    F --&gt; H{{HPC1}}:::thirdclass\n    F --&gt; I{{HPC2}}:::thirdclass  \n    classDef someclass stroke:#f00\n    classDef otherclass stroke:#0f0\n    classDef thirdclass stroke:#00f\n\n\n\n\n\n\n\n\n\nFigure 3: Machine-centered view: Supply chain model for the CDT. For a given job, the dataset (stored in one of two Datacentres, \\(\\mathrm{DC}_1\\) or \\(\\mathrm{DC}_2\\)) can be processed on one of two HPC centres (\\(\\mathrm{HPC}_1\\) or \\(\\mathrm{HPC}_2\\)), and ouput data is sent to (and stored on) one of the two Datacentres, ready as input for the next job. This is repeated for each job in the ordered job list (DAG).\n\n\n\n\n\n\n\n\n\nFigure 4: The CDT model is based on RCPSP and SCND.",
    "crumbs": [
      "Theory"
    ]
  },
  {
    "objectID": "theory.html#supply-chain-network-design-with-resource-constrained-scheduling",
    "href": "theory.html#supply-chain-network-design-with-resource-constrained-scheduling",
    "title": "Theory",
    "section": "Supply Chain Network Design with Resource Constrained Scheduling",
    "text": "Supply Chain Network Design with Resource Constrained Scheduling\n\nProblem Definition\nThe resource-constrained project scheduling problem is a classical, well-known problem in operations research, and started with the CPM4 that was developed in the 1950’s. A number of activities are to be scheduled. Each activity has a duration and cannot be interrupted. There are a set of precedence relations between pairs of activities which state that the second activity must start after the first has finished.\n4 Critical Path MethodThe set of precedence relations are usually given as a directed acyclic graph (DAG), where the edge \\((i,j)\\) represents a precedence relation where job \\(i\\) must finish before job \\(j\\) begins. The DAG contains two additional dummy activities with duration 0, the source and sink, where the source is the first activity and the sink is the last activity.\nThere are also sets of renewable resources and non-renewable resources. Each resource has a maximum capacity and at any given time slot no more than this amount can be in use. Each activity has a demand (possibly zero) on each resource. The dummy source and sink activities have zero demand on all resources.\nMulti-Mode Variant The multi-mode resource-constrained project scheduling problem5 is an extension of the resource-constrained project scheduling problem where each task can be executed in one of a number of alternative modes. The problem aims to select a single task mode from a set of available modes in order to construct a precedence- and resource-feasible project schedule with a minimal makespan. This is similar to a supply chain.\n5 MRCPSPNon-Renewable Resources Another extension concerns non-renewable resources. Each non-renewable resource has a capacity for the entire schedule. An example would be a financial, or human resources budget that applies to the entire project. Modes of activities must be chosen to avoid exceeding the total capacity of each of the non-renewable resources.\nTime Windows Instead of optimizing over the maximum value of the project timespan, we can use time windows. The benefit of time windows is twofold: first, they can be used in the mathematical programming formulation to reduce the number of variables substantially, i.e. they provide a tighter formulation. Second, they can be utilized in several enumeration procedures to speed up the convergence of the underlying optimization algorithms.\n\n\nState Variables\nThe state of the system at a given time \\(t,\\) is represented by a set of binary-valued state variables that designate the facilities that are used, at each stage, by each job to be performed in the workflow.\n\n\nObjective Function\nThe overall objective is to combine location decisions—which centres to use—with allocation decisions—how to distribute the workloads and jobs among the chosen centres (data and compute). Various project performance metrics can be optimized, including task-based, resource-based, financial-based and user-based metrics. One can minimize makespan, tardiness, resource consumption, or maximize total NPV with respect to sustainability, for example.\nThere can be a single objective such as minimizing (any function of) the total of fixed and variable costs, or minimizing the completion time (makespan). Multiple objective optimization6 seeks a tradeoff between minimum cost and maximum sustainability (minimum environmental impact). Finally, stochastic optimization takes into account the uncertainties of resource availabilities and delays, maintenance and failures, resource allocations, variable energy costs, project costs (HR, budget).\n6 MOO7 Some terms can be ignored by setting the coefficients to zero, depending on the context.The overall, deterministic cost function can be expressed either as a bottleneck objective, where we seek to minimize the longest or most expensive job, or as a weighted sum over all jobs of makespan, cost and any functions of these.7\nFor example, suppose we have \\(m\\) machines \\(\\{M_j\\}_{j=1}^{m}\\) to process \\(n\\) jobs \\(\\{J_i\\}_{i=1}^{n}.\\) A job \\(J_i\\) can eventually be broken down into \\(n_i\\) operations \\(O_{i1},\\ldots,O_{in_i},\\) each with its own processing requirement \\(p_{ij}.\\)\nObjective Functions Denote the finishing time of job \\(J_i\\) by \\(C_i\\) and the associated cost \\(f_i(C_i).\\) Then there are two types of total cost functions, the bottleneck objective \\[\n   f_{\\mathrm{max}}(C) \\doteq \\max \\{f_i(C_i) \\mid i=1,\\ldots,n\\}\n\\] and the sum objective \\[\n   \\sum f_i(C) \\doteq  \\sum_{i=1}^{n} f_i(C_i).\n\\] The sum can also be weighted, if required.\n\n\nMathematical Formulation - Deterministic Model\nResource-Constrained Project Scheduling Problem (RCPSP)\nThe Resource-Constrained Project Scheduling Problem (RCPSP) is an NP-hard combinatorial optimization problem that consists of finding a feasible scheduling for a set of \\(n\\) jobs subject to resource and precedence constraints. Each job has a processing time, a set of successor jobs and a required amount of different resources. Resources may be scarce but are renewable at each time period. Precedence constraints between jobs mean that no jobs may start before all its predecessors are completed. The jobs must be scheduled non-preemptively, i.e., once started, their processing cannot be interrupted.\nThe RCPSP has the following input data:\n\n\\(\\mathcal{J} = \\{J_1, J_2, \\ldots, J_n \\}\\) set of jobs.\n\\(\\mathcal{R}\\) set of renewable resources.\n\\(\\mathcal{S}\\) set of precedences8 between jobs \\((i,j)\\in\\mathcal{J}\\times\\mathcal{J}.\\)\n\\(\\mathcal{T}\\) planning horizon: set of possible processing times for jobs.\n\\(p_{j}\\) processing time of job \\(j.\\)\n\\(u_{jr}\\) amount of (renewable) resource \\(r\\) required for processing job \\(j.\\)\n\\(c_{r}\\) capacity of renewable resource \\(r.\\)\n\n8 These can be rigorously defined using an order relation, \\(i \\prec j\\).9 An alternative formulation, based on disjunctions will be presenetd in the Examples—see Implementation.There are many different Mixed Integer Linear Programming (MILP) formulations for the RCPSP. We choose the most suitable, discrete-time (DT) formulation9. This is a binary formulation where we have a binary variable \\(x_{i,t}\\) for each activity \\(i\\) and starting time/date \\(t,\\)\n\\[ x_{i,t} = \\begin{cases} 1, \\quad \\text{if activity $i$ starts on day/time $t,$} \\\\ 0, \\quad  \\text{otherwise.}  \\end{cases} \\]\nThe binary programming formulation, proposed by Pritsker et al. in 1986 can be written as follows.\n\\[\n\\begin{align}\n\\text{Minimize} \\quad &  \\sum_{t\\in \\mathcal{T}} t\\cdot x_{n+1,t} & (1)\\\\\n\\text{Subject to:} \\quad &\n\\sum_{t\\in \\mathcal{T}} x_{j,t}  = 1  \\,\\,\\, \\forall j\\in J & (2)\\\\\n& \\sum_{j\\in J} \\sum_{t_2=t-p_{j}+1}^{t} u_{jr}x_{j,t_2}  \\leq c_{r}  \\,\\,\\, \\forall t\\in \\mathcal{T}, r \\in R & (3) \\\\\n& \\sum_{t\\in \\mathcal{T}} t\\cdot x_{s,t} - \\sum_{t \\in \\mathcal{T}} t\\cdot x_{j,t}  \\geq p_{j}  \\,\\,\\, \\forall (j,s) \\in S & (4)\\\\\n& x_{j,t}  \\in \\{0,1\\} \\,\\,\\, \\forall j\\in J, t \\in \\mathcal{T} & (5)\n\\end{align}\\]\nThe objective function (1) represents the sum of all possible start dates for the final sink job (dummy variable) \\(x_{n+1,t}.\\) We know that only one of these variables will equal 1 for a specific \\(t.\\) Therefore, by minimizing the sum of the product \\(t \\cdot x_{n+1,t},\\) we are effectively minimizing the total project duration. Constraint (2) ensures that each activity \\(i\\) has exactly one start date, i.e. a single execution. Constraint (3) guarantees that for any time period \\(t,\\) the schedule does not exceed the capacity \\(R_k\\) for any resource \\(k.\\) Finally, constraint (4) ensures that if an activity \\(j\\) follows another activity \\(i,\\) then activity \\(j\\) must start after the finish time of activity \\(i,\\) which is equal to the start time of activity \\(i\\) plus its duration \\(p_i.\\)\nMutli-Project Multi-Mode RCPSP\nNote that the above formulation is restricted to temporal scheduling on a single machine, and for a single project—a collection of jobs. This formulation can be generalized to deal with multiple machines and multiple projects. In this case, the formulation becomes very similar to that of a supply chain. It is referred to in the literature as the multi-mode resource-constrained multi-project scheduling problem, or MRCMPSP.\nMulti-Mode The single-mode RCPSP assumed that each activity has only one way to be executed, whereas the multi-mode RCPSP considers multiple ways to execute an activity, which often have tradeoffs in duration, cost, or resource requirement.\nLet the decision variable \\(x_{jm,t} \\in \\{0,1 \\}\\) denote the execution of job \\(j\\) in mode \\(m\\) completed in period \\(t.\\) Then the MRCPSP with tight, time-indexed formulation10 can be written as:\n10 A disjunctive formulation, based on XOR relations, is also possible—see Implementation\\[\n\\begin{align}\n\\min \\quad &  \\sum_{t=\\mathrm{EF}_J}^{\\mathrm{LF}_J} t\\cdot x_{J1,t} & (1)\\\\\n\\text{s.t.} \\quad &\n\\sum_{m=1}^{M_j}  \\sum_{t=\\mathrm{EF}_J}^{\\mathrm{LF}_J} x_{jm,t}  = 1,  \\,\\,\\, j=1,\\ldots, J ,& (2)\\\\\n& \\sum_{m=1}^{M_j} \\sum_{t=\\mathrm{EF}_h}^{\\mathrm{LF}_h} t \\cdot x_{hm,t} \\le \\sum_{m=1}^{M_j}\\sum_{t=\\mathrm{EF}_j}^{\\mathrm{LF}_j} (t - p_{jm}) \\cdot x_{jm,t},  \\,\\,\\, j=2,\\ldots, J, \\, h \\in \\mathcal{P}_j , & (3)\\\\\n& \\sum_{j=2}^{J-1} \\sum_{m=1}^{M_j} k_{jmr}^{\\rho} \\sum_{q=\\max\\{t,\\mathrm{EF}_j\\} }^{\\min \\{ t+p_{jm}-1,\\mathrm{LF}_j \\}}  x_{jm,q} \\le K_r^{\\rho}, \\,\\,\\,  r\\in R^{\\rho}, \\, t=1,\\ldots, \\bar{T}, & (4) \\\\\n& \\sum_{j=2}^{J-1} \\sum_{m=1}^{M_j} k_{jmr}^{\\nu}   \\sum_{t=\\mathrm{EF}_J}^{\\mathrm{LF}_J}  x_{jm,t} \\le K_r^{\\nu}, \\,\\,\\, r\\in R^{\\nu},  & (5)\\\\\n& x_{jm,t}  \\in \\{0,1\\}, \\,\\,\\, j=1,\\ldots,J, \\, m=1,\\ldots ,M_j, \\, t =0,\\ldots, \\bar{T}, & (6)\n\\end{align}\\] where \\(\\mathcal{P}_j\\) is the set of predecessors of job \\(j,\\) the earliest finish and latest finish times of job \\(j\\) are denoted \\(\\mathrm{EF}_j,\\) \\(\\mathrm{LF}_j,\\) an upper bound on the project’s makespan is given by \\(\\bar{T}\\), and we have denoted renewable resources by the index \\(\\rho\\) and non-renewables by \\(\\nu.\\)\nNote that objective (1) is the minimization of the makespan11, the constraints (2) indicate that each activity is assigned exactly one mode and exactly one finish time, (3) ensures that no activity is started until all its predecessors are finished, (4) ensures that the per-period levels of the renewable resources are met, and consumption of the nonrenewable resources is limited to their availabilities by (5). Finally, restricting the summations12 over time to the intervals \\([\\mathrm{EF}_j, \\mathrm{LF}_j]\\) reduces drastically the number of variables and gives better convergence. These time windows can be computed by simple forward and backward recursion loops.\n11 To which we can add any cost function of the duration.12 This produces what is known as a tighter formulation.13 Or terms, if other costs are to be taken into account, e.g. related to sustainabilityMulti-Objective To include infrastructure costs in the objective function, we just add a term13 \\[\\begin{align}\n\\min \\quad &  \\sum_{t=\\mathrm{EF}_J}^{\\mathrm{LF}_J} t\\cdot x_{J1,t}\n                  + \\sum_{j,m} c_{jm} x_{jm} & (1')\\\\\n\\end{align}\\] where \\(c_m\\) is the cost associated with the use of facility \\(m\\) for task \\(j.\\)\nMulti-Project We can also perform simultaneous scheduling of a set of multiple projects taking into account the availability of local and global resources under different time and resource constraints. This has practical importance, at national and European levels, when cross-facility implies exploitation of cyberinfrastructure resources across different countries, for example, as would be the case for EuroHPC14, at the European level, or GENCI15 for France. Imagine being able to plan and pilot multiple exascale projects, on multiple sites, over multiple countries…16\n14  https://www.eurohpc-ju.europa.eu/ 15  https://www.genci.fr// 16 These would be multiple states, in the USA context.17 SCCPConclusion This general formulation of the RCPSP is then mathematically equivalent to the supply chain configuration problem17 with the addition of resource constraints. The loop is closed.",
    "crumbs": [
      "Theory"
    ]
  },
  {
    "objectID": "theory.html#dynamic-networks",
    "href": "theory.html#dynamic-networks",
    "title": "Theory",
    "section": "Dynamic Networks",
    "text": "Dynamic Networks\nWe can generalize the supply chain by considering a multi-stage network with an added time dimension. This enables flow and carrying of data and jobs across time periods, in addition to flow among facilities. For example, if certain facilites become unavailable, or less available, as the project evolves over time. This is a kind of recourse, which will be considered below in Section Uncertainty.\n\n\n\n\n\n\n\n\nflowchart LR\n    subgraph t1[\"t = 1\"]\n    direction LR\n    a1((\" \"))--&gt;a2((\" \"))\n    a1--&gt;a3((\" \"))\n    a2--&gt;a4((\" \"))\n    a2-.-&gt;a5((\" \"))\n    end\n    subgraph t2[\"t = 2\"]\n    direction LR\n    b1((\" \"))--&gt;b2((\" \"))\n    b1--&gt;b3((\" \"))\n    b2-.-&gt;b4((\" \"))\n    b2--&gt;b5((\" \"))\n    end\n    t1 --&gt; t2\n    style t1 fill: white\n    style t2 fill: white\n\n\n\n\n\n\n\n\nFigure 5: Multi-stage, dynamic network that evolves over time due to changing availability constraints.",
    "crumbs": [
      "Theory"
    ]
  },
  {
    "objectID": "theory.html#sec-stoch",
    "href": "theory.html#sec-stoch",
    "title": "Theory",
    "section": "Uncertainty",
    "text": "Uncertainty\nIn practice some of the scheduling parameters may be uncertain. The exact duration of an activity, for instance, might not be known at the beginning of the project. Similarly, the number of available resources is another parameter that may not be known before project execution. These uncertainties may be due to different sources, including estimation errors, unforeseen (weather) conditions, late “delivery” (unavailability) of some required resources, unpredictable incidents such as machine breakdown or worker accidents, etc.\n\nStochastic, multistage programming\nBackground\nStochastic programming/optimization (optimal decision-making under uncertainty) is the part of mathematical programming and operations research that studies how to incorporate uncertainty into decision problems. Stochastic programs are primarily about transient decision making.\n\n\n\nInformation:\n\n\nSome decisions must be made today, but important information will not be available until after the decision is made.\n\n\nAn information stage (normally simply called “stage”) is the most important concept that distinguishes stochastic programming. A stage is a point in time where decisions are made within a model. Stages define the boundaries of time intervals. Stages sometimes follow naturally from the problem setting and sometimes are modeling approximations.\nThe starting point of a stochastic program is the present situation. The model is intended to tell us what to do in light of our goals, constraints, and resources. We then ask what we should do. We are not asking what to do in all possible situations, just what to do based on our present state.\n\nAn inherently two-stage model is a model where the first decision is a major long-term decision, whereas the remaining stages represent the use of this investment. In these cases, mathematically speaking, the first stage will look totally different from the remaining stages, which will all look more or less the same. This is a very important class of models, possibly the most important one for stochastic programming.\nIn inherently multistage models, all stages are of the same type. We face random resource availability, energy prices, unexpected maintenance, etc. We should not confuse information stages with time periods. Stages model the flow of information; time periods represent the ticking of the clock in a model. Stages, on the other hand, are points in time where we make decisions in the model after having learned something new.\n\nFinding a good trade-off between time periods and stages is often crucial when modeling, as it has consequences for model quality, data collection, and solvability of the model.\n\n\n\nWarning/Fact:\n\n\nIn the long run we are all dead.\n\n\n- John Maynard Keynes (A Tract on Monetary Reform, 1923)\n\n\n\nIn other words, one should not wait too long before taking a decision.\nMathematical Formulation\n\n\n\n\n\n\nFigure 6: A multistage decision process with uncertainty. Uncertain, exogenous inputs \\(\\xi_t\\) arrive, starting from stage \\(t=2,\\) and trigger subsequent recourse actions.\n\n\n\nIn the Figure we depict a generic multistage decision process with state \\(\\mathbf{x}_t\\) that evolves over time, starting at stage \\(t=1,\\) and then receives uncertain, exogenous inputs, \\(\\xi_2, \\xi_3, \\ldots, \\xi_T,\\) at given stages \\(t = 2,3,\\ldots, T.\\) At stage 1, a here-and-now (deterministic) decision is taken. The subsequent sequence of wait-and-see decision functions \\({\\mathbf{x}_t(\\xi_t)}_{t\\in [T]}\\) constitutes a policy, \\(\\pi.\\) The policy thus obtained, provides a decision rule for all stages \\(t \\in [T].\\) The aim of the decision process (stochastic multistage optimization) is then to compute an optimal policy for a given objective and subject to constraints.\nWe will describe in detail the two-stage problem, since the multistage is a straightforward generalisation. In the stochastic setting, we can naturally classify \\(x\\in\\mathscr{X}\\) as the first-stage decision variables, since the initial facilities18 are fixed and \\(y\\in\\mathbb{R}^{\\left|\\mathscr{A}\\right|\\times\\left|\\mathscr{K}\\right|}\\) as the second-stage decision variables, since the job-flow operating conditions are uncertain over time.\n18 Data centers, HPC centers, networks. The two-stage stochastic linear program (Birge and Louveaux 2011), (Shapiro, Dentcheva, and Ruszczyński 2009) is then\n\\[\\begin{align} \\label{eq:2stage}\n\\min_{x\\in\\mathscr{X}} & \\,\\,c^{\\top}x + \\mathrm{E}\\left[Q(x;\\xi)\\right],\n\\end{align}\\] where \\(Q(x;\\xi)\\) is the optimal value of the second-stage problem \\[\\begin{align*}\n\\min_{y\\ge0} & \\,\\,q^{\\top}y\\\\\n\\textrm{s.t.} & \\,\\,Ny=0,\\\\\n& Cy\\ge d,\\\\\n& Sy\\le s,\\\\\n& Ry\\le Mx,\n\\end{align*}\\] where \\(d\\) is the (uncertain) resource demand, \\(s\\) is the (uncertain) resource supply, the random vector \\(\\xi=(q,d,s,R,M)\\) and \\(y=y(\\xi).\\) The expectation is taken with respect to the joint probability distribution function19 of \\(\\xi.\\) In the terminology of state-space, we can consider \\(x\\) as the state variable, and \\(y\\) as the control variable.\n19 Either continuous or discrete, it is derived either from theory or observations, or both.To treat the occurrence of infeasibility, where the first-stage solution does not satisfy the second-stage constraints, e.g. \\(Cy\\nleqslant d,\\) we introduce a recourse action \\(z\\) that supplies the deficit \\(d-Cy\\) at some penalty cost. Then the second-stage problem becomes \\[\\begin{align*}\n\\min_{y\\ge0} & \\,\\,q^{\\top}y+h^{\\top}z\\\\\n\\textrm{s.t.} & \\,\\,Ny=0,\\\\\n& Cy+z\\ge d,\\\\\n& Sy\\le s,\\\\\n& Ry\\le Mx,\n\\end{align*}\\] where \\(h\\) represents the vector of (positive) recourse costs.\nIn the multistage case, we will have a succession of recourse stages, yielding the multistage program (Powell 2022),\n\\[\n    \\min_{\\pi \\in \\Pi} \\mathrm{E} \\left[ \\sum^{T}_{t=1} \\gamma^{t-1} f_t(x_t;\\xi_t) \\right],\n\\] subject to \\[\n     x_t \\in \\mathcal{X}_t(x_{t-1};\\xi_{t-1}), \\quad t=1 \\ldots, T,\n\\] where \\(\\pi\\) is a policy, \\(\\gamma\\) is a discount factor, \\(f_t\\) is a cost function, \\(x_t\\) is a decision and \\(\\mathcal{X}_t\\) are the constraints. A policy is, by definition, a method that optimizes the objective. For example, in Google maps, the policy is to decide whether to turn left or right by optimizing over the time required to transverse the next link in the network plus the remaining time to get to the destination.\nNote that there are various forms of minimization in stochastic scheduling. Whenever an objective function has to be minimized, it has to be specified in what sense the objective has to be minimized.\n\nExpectation sense is the crudest form of optimization, e.g., one wishes to minimize (a function of) the expected makespan, that is \\(\\mathrm{E}\\left[f\\left(C_{\\mathrm{max}}\\right)\\right],\\) and find a policy under which the expected makespan is smaller than the expected makespan under any other policy.\nStochastic sense is a stronger form of optimization. If a schedule or policy minimizes \\(f\\left(C_{\\mathrm{max}}\\right)\\) stochastically, then the makespan under the optimal schedule or policy is stochastically (in probability, or in law) less than the makespan under any other schedule or policy.\n\n\n\n\n\nBirge, John R., and François Louveaux. 2011. Introduction to Stochastic Programming. Second edition. Springer New York, NY. https://doi.org/10.1007/978-1-4614-0237-4.\n\n\nPowell, Warren B. 2022. Reinforcement Learning and Stochastic Optimization: A Unified Framework for Sequential Decisions. John Wiley & Sons.\n\n\nShapiro, Alexander, Darinka Dentcheva, and Andrzej Ruszczyński. 2009. Lectures on Stochastic Programming. SIAM, Society for Industrial; Applied Mathematics. https://doi.org/10.1137/1.9780898718751.",
    "crumbs": [
      "Theory"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Optimal Scheduling for Cross-Facility Workflows",
    "section": "",
    "text": "Welcome\nThis (online) user-guide contains a complete presentation of optimal scheduling applied to Exascale and post-Exascale workflows. These workflows combine data acquisition, data storage, data transfer and data analysis. The HPC components of such workflows can incorporate a diverse range of models, including partial differential equation solvers, algebraic solvers, AI/ML-based models, and data analytics components, all integrated into a single process (Ferreira da Silva et al. 2024), (Unat et al. 2025).\nThe objective here is to address the inherent cross-facility, multi-domain character of these workflows. This requires a very carefully-crafted theoretical foundation that can be readily generalized and extended to these contexts. The material covers both the theory and its application to practical use-cases, including real contexts with uncertainties emanating from different causes. To understand these well, numerous examples are provided in the form of python code snippets and jupyter notebooks. All of these are intgerated in a digital twin1 of the underlying cyberinfrastructure, the so-called digital continuum.\nThe Continuum Digital Twin (CDT) is defined and described in the series of forthcoming papers (Garénaux-Gruau, Bodin, and Asch 2025a, 2025b, 2025c). For optimization and scheduling, there are numerous excellent references. Among these we point out particularly (Birge and Louveaux 2011), (Pinedo 2022), and (Powell 2022). Most of the codes are based on the wonderful pyomo framework (Bynum et al. 2021), (Hart, Watson, and Woodruff 2011) and (Postek et al. 2025). General background on exascale workflows can be found in (M. Asch et al. 2018).",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#author",
    "href": "index.html#author",
    "title": "Optimal Scheduling for Cross-Facility Workflows",
    "section": "Author",
    "text": "Author\nMark Asch is Emeritus Professor of the Université de Picardie Jules Verne, Mathematics department.\n https://markasch.github.io/DT-tbx-v1/\n https://github.com/markasch/\n http://masch.perso.math.cnrs.fr/\n mark.asch@u-picardie.fr",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#citation",
    "href": "index.html#citation",
    "title": "Optimal Scheduling for Cross-Facility Workflows",
    "section": "Citation",
    "text": "Citation\nAsch, Mark. Optimal Scheduling for Cross-Facility Workflows. Online (2026) https://markasch.github.io/RCP4CDT/\n@book{Asch2026\n    title = {Optimal {S}cheduling for {C}ross-{F}acility {W}orkflows},\n    author = {Asch, Mark},\n    url = {https://markasch.github.io/RCP4CDT/},\n    year = {2026},\n    publisher = {Online}\n}",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#license",
    "href": "index.html#license",
    "title": "Optimal Scheduling for Cross-Facility Workflows",
    "section": "License",
    "text": "License\nThis online book is frequently updated and edited. It’s content is free to use, licensed under a Creative Commons licence, and the code can be found on GitHub. A physical copy of the book will be available at a later date.\nLicense: Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#references",
    "href": "index.html#references",
    "title": "Optimal Scheduling for Cross-Facility Workflows",
    "section": "References",
    "text": "References\n\n\nAsch, Mark. 2022. A Toolbox for Digital\nTwins: From\nModel-Based to\nData-Driven. Philadelphia, PA: Society\nfor Industrial; Applied Mathematics. https://doi.org/10.1137/1.9781611976977.\n\n\nAsch, M, T Moore, R Badia, M Beck, P Beckman, T Bidot, F Bodin, et al.\n2018. “Big Data and Extreme-Scale Computing: Pathways to\nConvergence-Toward a Shaping Strategy for a Future Software and Data\nEcosystem for Scientific Inquiry.” The International Journal\nof High Performance Computing Applications 32 (4): 435–79. https://doi.org/10.1177/1094342018778123.\n\n\nBirge, John R., and François Louveaux. 2011. Introduction to\nStochastic Programming. Second edition. Springer New\nYork, NY. https://doi.org/10.1007/978-1-4614-0237-4.\n\n\nBynum, Michael L., Gabriel A. Hackebeil, William E. Hart, Carl D. Laird,\nBethany L. Nicholson, John D. Siirola, Jean-Paul Watson, and David L.\nWoodruff. 2021. Pyomo–Optimization Modeling in Python. Third.\nVol. 67. Springer Science & Business Media.\n\n\nFerreira da Silva, Rafael, Rosa M. Badia, Deborah Bard, Ian T. Foster,\nShantenu Jha, and Frederic Suter. 2024.“Frontiers in Scientific Workflows: Pervasive Integration\nWith High-Performance Computing .” Computer 57\n(08): 36–44. https://doi.org/10.1109/MC.2024.3401542.\n\n\nGarénaux-Gruau, Marius, François Bodin, and Mark Asch. 2025a.\n“Continuum Digital Twin Implementation.” https://arxiv.org/abs/25xx.xxxx.\n\n\n———. 2025b. “Continuum Digital Twin Use Cases.” https://arxiv.org/abs/25xx.xxxx.\n\n\n———. 2025c. “Continuum Digital Twin—Mathematical Models.”\nhttps://arxiv.org/abs/25xx.xxxx.\n\n\nHart, William E, Jean-Paul Watson, and David L Woodruff. 2011.\n“Pyomo: Modeling and Solving Mathematical Programs in\nPython.” Mathematical Programming Computation 3 (3):\n219–60.\n\n\nIEA, Paris. 2025. “Energy and AI.” https://www.iea.org/reports/energy-and-ai.\n\n\nPinedo, Michael L. 2022. Scheduling: Theory, Algorithms, and\nSystems. 6th edition. Springer Cham.\n\n\nPostek, Krzysztof, Alessandro Zocca, Joaquim Gromicho, and Jeffrey\nKantor. 2025. Hands-On Mathematical\nOptimization with Python. Cambridge University Press. https://doi.org/10.1017/9781009493512.\n\n\nPowell, Warren B. 2022. Reinforcement Learning and Stochastic\nOptimization: A Unified Framework for Sequential Decisions. John\nWiley & Sons.\n\n\nShapiro, Alexander, Darinka Dentcheva, and Andrzej Ruszczyński. 2009.\nLectures on Stochastic Programming.\nSIAM, Society for Industrial; Applied Mathematics. https://doi.org/10.1137/1.9780898718751.\n\n\nUnat, Didem, Anshu Dubey, Emmanuel Jeannot, and John Shalf. 2025.\n“The Persistent Challenge of Data Locality in the Post-Exascale\nEra.” Computing in Science & Engineering 27 (4):\n19–27. https://doi.org/10.1109/MCSE.2025.3567586.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "examples.html#data-model-overview",
    "href": "examples.html#data-model-overview",
    "title": "Implementation",
    "section": "Data Model Overview",
    "text": "Data Model Overview\nThe input consists of four entities:\n\n\n\n\n\n\n\nEntity\nDescription\n\n\n\n\nResources\nAvailable resources with capacities (renewable per period, non-renewable)\n\n\nJobs\nUnits of work to be scheduled\n\n\nModes\nAlternative execution options for each job\n\n\nPrecedences\nDirected edges defining the execution order (DAG)\n\n\n\n\n1. Resources\n\n\n\n\n\n\n\n\n\nField\nType\nRequired\nDescription\n\n\n\n\nresource_id\nstring\nyes\nUnique identifier for the resource\n\n\nname\nstring\nno\nHuman-readable name\n\n\ncapacity\ninteger ≥ 0\nyes\nMaximum units available per time period6\n\n\n\n6 For renewable resources. If resource is non-renewable, this is the total available.\n\n2. Jobs\n\n\n\nField\nType\nRequired\nDescription\n\n\n\n\njob_id\nstring\nyes\nUnique identifier for the job\n\n\nname\nstring\nno\nHuman-readable name\n\n\nrelease_time\ninteger ≥ 0\nno\nEarliest start time (default: 0)\n\n\ndeadline\ninteger ≥ 0\nno\nLatest finish time (default: none)\n\n\n\n\n\n3. Modes\nEach job must have at least one mode. A mode specifies how a job can be executed.\n\n\n\n\n\n\n\n\n\nField\nType\nRequired\nDescription\n\n\n\n\nmode_id\nstring\nyes\nUnique identifier for the mode\n\n\njob_id\nstring\nyes\nReference to parent job\n\n\nduration\ninteger ≥ 0\nyes\nProcessing time in periods\n\n\ncost\nfloat ≥ 0\nyes\nCost of selecting this mode\n\n\nresource_requirements\nlist\nyes\nResources consumed during execution\n\n\n\n\nResource Requirement (nested within Mode)\n\n\n\n\n\n\n\n\n\nField\nType\nRequired\nDescription\n\n\n\n\nresource_id\nstring\nyes\nReference to a defined resource\n\n\ndemand\ninteger ≥ 0\nyes\nUnits required per period while job executes\n\n\n\n\n\n\n4. Precedences\nDefines the DAG structure. Each entry represents a directed edge.\n\n\n\n\n\n\n\n\n\nField\nType\nRequired\nDescription\n\n\n\n\npredecessor\nstring\nyes\njob_id of the job that must finish first\n\n\nsuccessor\nstring\nyes\njob_id of the job that must start after\n\n\nlag\ninteger ≥ 0\nno\nMinimum time gap between finish and start (default: 0)\n\n\n\nThis gives the following json format.\n{\n  \"problem_name\": \"string (optional)\",\n  \"horizon\": \"integer (optional, planning horizon)\",\n  \n  \"resources\": [\n    {\n      \"resource_id\": \"string\",\n      \"name\": \"string (optional)\",\n      \"capacity\": \"integer\"\n    }\n  ],\n  \n  \"jobs\": [\n    {\n      \"job_id\": \"string\",\n      \"name\": \"string (optional)\",\n      \"release_time\": \"integer (optional, default 0)\",\n      \"deadline\": \"integer (optional, default null)\"\n    }\n  ],\n  \n  \"modes\": [\n    {\n      \"mode_id\": \"string\",\n      \"job_id\": \"string\",\n      \"duration\": \"integer\",\n      \"cost\": \"number\",\n      \"resource_requirements\": [\n        {\n          \"resource_id\": \"string\",\n          \"demand\": \"integer\"\n        }\n      ]\n    }\n  ],\n  \n  \"precedences\": [\n    {\n      \"predecessor\": \"string (job_id)\",\n      \"successor\": \"string (job_id)\",\n      \"lag\": \"integer (optional, default 0)\"\n    }\n  ]\n}\nValidation\nWe provide a JSON schema that the user can use for formal validation of their input files as follows.\nimport json\nimport jsonschema\nfrom jsonschema import validate\nimport DraftValidator\n\n# Load schema and data\nwith open(\"workflow-schema.json\") as f:\n    schema = json.load(f)\n\nwith open(\"my-problem.json\") as f:\n    data = json.load(f)\n\n# Validate\ntry:\n    validate(instance=data, schema=schema)\n    print(\"Input is valid.\")\nexcept jsonschema.ValidationError as e:\n    print(f\"Validation error: {e.message}\")\n    print(f\"Path: {list(e.absolute_path)}\")\n\n\nModel Function\nAll the above are necessary and sufficient for the mathematical formulation presented in the section Mathematical Formulation - Deterministic Model. We define a pyomo function that takes a dictionary of tasks as input7, and returns a pyomo model.\n7 See below for examples.# Model function generator\ndef MRCPSP_model(TASKS):\n    model = pyo.ConcreteModel()\n    # tasks is a two dimensional set of (j,m) constructed from the dictionary keys\n    model.TASKS = pyo.Set(initialize=TASKS.keys(), dimen=2)\n    # the set of jobs is constructed from a python set\n    model.JOBS = pyo.Set(initialize=list(set([j for (j, m) in model.TASKS])))\n    # set of machines is constructed from a python set\n    model.MACHINES = pyo.Set(initialize=list(set([m for (j, m) in model.TASKS])))\n    # the order of tasks is constructed as a cross-product of tasks and filtering\n    model.TASKORDER = pyo.Set(\n        initialize = model.TASKS * model.TASKS,\n        dimen      = 4,\n        filter     = lambda model, j, m, k, n: (k, n) == TASKS[(j, m)][\"prec\"],\n    )\n    # the set of disjunctions is cross-product of jobs, jobs, and machines\n    model.DISJUNCTIONS = pyo.Set(\n        initialize = model.JOBS * model.JOBS * model.MACHINES,\n        dimen      = 3,\n        filter     = lambda model, j, k, m: j &lt; k\n                     and (j, m) in model.TASKS\n                     and (k, m) in model.TASKS,\n    )\n    # load duration data into a model parameter for later access\n    @model.Param(model.TASKS)\n    def dur(model, j, m):\n        return TASKS[(j, m)][\"dur\"]\n    # establish an upper bound on makespan\n    ub = sum([model.dur[j, m] for (j, m) in model.TASKS])\n    # create decision variables\n    model.makespan = pyo.Var(bounds=(0, ub))\n    model.start = pyo.Var(model.TASKS, bounds=(0, ub))\n    \n    @model.Objective(sense=pyo.minimize)\n    def minimize_makespan(model):\n        return model.makespan\n    \n    @model.Constraint(model.TASKS)\n    def finish_tasks(model, j, m):\n        return model.start[j, m] + model.dur[j, m] &lt;= model.makespan\n\n    @model.Constraint(model.TASKORDER)\n    def preceding(model, j, m, k, n):\n        return model.start[k, n] + model.dur[k, n] &lt;= model.start[j, m]\n\n    @model.Disjunction(model.DISJUNCTIONS)\n    def no_overlap(model, j, k, m):\n        return [\n            model.start[j, m] + model.dur[j, m] &lt;= model.start[k, m],\n            model.start[k, m] + model.dur[k, m] &lt;= model.start[j, m],\n        ]\n\n    pyo.TransformationFactory(\"gdp.bigm\").apply_to(model)\n    return model\n# Generate the model\nMRCPSP_model(TASKS)\n\n\nOptimization\nThe optimization can be performed by calling one of the built-in solvers of pyomo, or by using one of the more efficient commercial8 solvers, from CPLEX or gurobi.\n8 Free academic versions are available.# model optimization\ndef MRCPSP_solve(model):\n    SOLVER.solve(model)\n    results = [\n        {\n            \"Job\": j,\n            \"Machine\": m,\n            \"Start\": model.start[j, m](),\n            \"Duration\": model.dur[j, m],\n            \"Finish\": model.start[(j, m)]() + model.dur[j, m],\n        }\n        for j, m in model.TASKS\n    ]\n    return results\n# select a suitable solver\nsolver = 'appsi_highs' #'gurobi' 'glpk','cbc','cplex'\nSOLVER = pyo.SolverFactory(solver)\nassert SOLVER.available(), f\"Solver {solver} is not available.\"\n# Solve the optimization problem\nresults = MRCPSP_solve(MRCPSP_model(TASKS))\n\n\nOutput\nFinally, we extract the schedule from the results, store them in a suitable dataframe, and output a CSV file with start and finish times of each job, as well as the optimal mode selected for each job. This can also be output in the form of a GANTT chart. Other outputs can include resource usage, energy consumption, machine utilization statistics and costs.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Implementation</span>"
    ]
  },
  {
    "objectID": "examples.html#tabular-definitions",
    "href": "examples.html#tabular-definitions",
    "title": "Implementation",
    "section": "Tabular Definitions",
    "text": "Tabular Definitions\n\n1. Resources\n\n\n\n\n\n\n\n\n\nField\nType\nRequired\nDescription\n\n\n\n\nresource_id\nstring\nyes\nUnique identifier for the resource\n\n\nname\nstring\nno\nHuman-readable name\n\n\ncapacity\ninteger ≥ 0\nyes\nMaximum units available per time period\n\n\n\n\n\n2. Jobs\n\n\n\nField\nType\nRequired\nDescription\n\n\n\n\njob_id\nstring\nyes\nUnique identifier for the job\n\n\nname\nstring\nno\nHuman-readable name\n\n\nrelease_time\ninteger ≥ 0\nno\nEarliest start time (default: 0)\n\n\ndeadline\ninteger ≥ 0\nno\nLatest finish time (default: none)\n\n\n\n\n\n3. Modes\nEach job must have at least one mode. A mode specifies how a job can be executed.\n\n\n\n\n\n\n\n\n\nField\nType\nRequired\nDescription\n\n\n\n\nmode_id\nstring\nyes\nUnique identifier for the mode\n\n\njob_id\nstring\nyes\nReference to parent job\n\n\nduration\ninteger ≥ 0\nyes\nProcessing time in periods\n\n\ncost\nfloat ≥ 0\nyes\nCost of selecting this mode\n\n\nresource_requirements\nlist\nyes\nResources consumed during execution\n\n\n\n\nResource Requirement (nested within Mode)\n\n\n\n\n\n\n\n\n\nField\nType\nRequired\nDescription\n\n\n\n\nresource_id\nstring\nyes\nReference to a defined resource\n\n\ndemand\ninteger ≥ 0\nyes\nUnits required per period while job executes\n\n\n\n\n\n\n4. Precedences\nDefines the DAG structure. Each entry represents a directed edge.\n\n\n\n\n\n\n\n\n\nField\nType\nRequired\nDescription\n\n\n\n\npredecessor\nstring\nyes\njob_id of the job that must finish first\n\n\nsuccessor\nstring\nyes\njob_id of the job that must start after\n\n\nlag\ninteger ≥ 0\nno\nMinimum time gap between finish and start (default: 0)\n\n\n\n\n\n\nModel Function\nAll the above are necessary and sufficient for the mathematical formulation presented in the section Mathematical Formulation - Deterministic Model. We define a pyomo function that takes a dictionary of tasks as input6, and returns a pyomo model.\n6 See below for examples.# Model function generator\ndef MRCPSP_model(TASKS):\n    model = pyo.ConcreteModel()\n    # tasks is a two dimensional set of (j,m) constructed from the dictionary keys\n    model.TASKS = pyo.Set(initialize=TASKS.keys(), dimen=2)\n    # the set of jobs is constructed from a python set\n    model.JOBS = pyo.Set(initialize=list(set([j for (j, m) in model.TASKS])))\n    # set of machines is constructed from a python set\n    model.MACHINES = pyo.Set(initialize=list(set([m for (j, m) in model.TASKS])))\n    # the order of tasks is constructed as a cross-product of tasks and filtering\n    model.TASKORDER = pyo.Set(\n        initialize = model.TASKS * model.TASKS,\n        dimen      = 4,\n        filter     = lambda model, j, m, k, n: (k, n) == TASKS[(j, m)][\"prec\"],\n    )\n    # the set of disjunctions is cross-product of jobs, jobs, and machines\n    model.DISJUNCTIONS = pyo.Set(\n        initialize = model.JOBS * model.JOBS * model.MACHINES,\n        dimen      = 3,\n        filter     = lambda model, j, k, m: j &lt; k\n                     and (j, m) in model.TASKS\n                     and (k, m) in model.TASKS,\n    )\n    # load duration data into a model parameter for later access\n    @model.Param(model.TASKS)\n    def dur(model, j, m):\n        return TASKS[(j, m)][\"dur\"]\n    # establish an upper bound on makespan\n    ub = sum([model.dur[j, m] for (j, m) in model.TASKS])\n    # create decision variables\n    model.makespan = pyo.Var(bounds=(0, ub))\n    model.start = pyo.Var(model.TASKS, bounds=(0, ub))\n    \n    @model.Objective(sense=pyo.minimize)\n    def minimize_makespan(model):\n        return model.makespan\n    \n    @model.Constraint(model.TASKS)\n    def finish_tasks(model, j, m):\n        return model.start[j, m] + model.dur[j, m] &lt;= model.makespan\n\n    @model.Constraint(model.TASKORDER)\n    def preceding(model, j, m, k, n):\n        return model.start[k, n] + model.dur[k, n] &lt;= model.start[j, m]\n\n    @model.Disjunction(model.DISJUNCTIONS)\n    def no_overlap(model, j, k, m):\n        return [\n            model.start[j, m] + model.dur[j, m] &lt;= model.start[k, m],\n            model.start[k, m] + model.dur[k, m] &lt;= model.start[j, m],\n        ]\n\n    pyo.TransformationFactory(\"gdp.bigm\").apply_to(model)\n    return model\n# Generate the model\nMRCPSP_model(TASKS)\n\n\nOptimization\nThe optimization can be performed by calling one of the built-in solvers of pyomo, or by using one of the more efficient commercial7 solvers, from CPLEX or gurobi.\n7 Free academic versions are available.# model optimization\ndef MRCPSP_solve(model):\n    SOLVER.solve(model)\n    results = [\n        {\n            \"Job\": j,\n            \"Machine\": m,\n            \"Start\": model.start[j, m](),\n            \"Duration\": model.dur[j, m],\n            \"Finish\": model.start[(j, m)]() + model.dur[j, m],\n        }\n        for j, m in model.TASKS\n    ]\n    return results\n# Solve the optimization problem\nresults = MRCPSP_solve(MRCPSP_model(TASKS))\n\n\nOutput\nFinally, we extract the schedule from the results, store them in a suitable dataframe, and output a CSV file with start and finish times of each job, as well as the optimal mode selected for each job. This can also be output in the form of a GANTT chart. Other outputs can include resource usage, energy consumption, machine utilization statistics and costs.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Implementation</span>"
    ]
  }
]