# Uncertainty {#sec-stoch}

In practice some of the scheduling parameters may be uncertain. The exact duration of an activity, for instance, might not be known at the beginning of the project. Similarly, the number of available resources is another parameter that may not be known before project execution. These uncertainties may be due to different sources, including estimation errors, unforeseen (weather) conditions, late "delivery" (unavailability) of some required resources, unpredictable incidents such as machine breakdown or worker accidents, etc. 

## Stochastic, multistage programming

**Background**

Stochastic programming/optimization (optimal decision-making under
uncertainty) is the part of mathematical programming and operations
research that studies how to incorporate uncertainty into decision
problems. Stochastic programs are primarily about transient decision
making.

::: {.callout-important}
Some decisions must be made today, but important information will not be available until after the decision is made.
:::

An _information stage_ (normally simply called “stage”)
is the most important concept that distinguishes stochastic programming.  A stage is a point in time where decisions are made within a model. Stages define the boundaries of time intervals. Stages sometimes follow naturally from the problem setting and sometimes are modeling approximations.


The starting point of a stochastic program is the present situation.
The model is intended to tell us what to do in light of our goals,
constraints, and resources. We then ask what we should do. We are not asking what to do in all
possible situations, just what to do based on our present state.

- An inherently _two-stage model_ is a model where
the first decision is a major long-term decision, whereas the remaining
stages represent the use of this investment. In these cases, mathematically
speaking, the first stage will look totally different from the remaining
stages, which will all look more or less the same. This is a very
important class of models, possibly the most important one for stochastic
programming.
- In inherently _multistage models_, all stages
are of the same type. We face random resource availability, energy prices, unexpected maintenance, etc.
We should not confuse information stages with time periods. Stages model the flow of
information; time periods represent the ticking of the clock in a
model. Stages, on the other hand, are points in time where
we make decisions in the model after having learned something new.

Finding a good trade-off between time periods
and stages is often crucial when modeling, as it has consequences
for model quality, data collection, and solvability of the model. 

::: {.callout-caution}
In the long run we are all dead. (J.M. Keynes)
:::

In other words, one should not wait too long before taking a decision.

**Mathematical Formulation**

::: {#fig-sdp}
![](graphics/sdp.png){width=80%}

A multistage decision process with uncertainty. Uncertain, exogenous inputs $\xi_t$ arrive, starting from stage $t=2,$ and trigger subsequent recourse actions.
:::

In the Figure we depict a generic multistage  decision process with state $\mathbf{x}_t$ that evolves over time, starting at stage $t=1,$ and then receives uncertain, exogenous inputs, $\xi_2, \xi_3, \ldots, \xi_T,$ at given stages $t = 2,3,\ldots, T.$ At stage 1, a here-and-now (deterministic) decision is taken. The subsequent sequence of wait-and-see decision functions ${\mathbf{x}_t(\xi_t)}_{t\in [T]}$ constitutes a _policy_, $\pi.$ The policy thus obtained, provides a decision rule for all stages $t \in [T].$ The aim of the decision process (stochastic multistage optimization) is then to compute an _optimal policy_  for a given objective and subject to constraints.

We will describe in detail the two-stage problem, since the multistage is a straightforward generalisation.  In the stochastic setting, we can naturally classify $x\in\mathscr{X}$ as the _first-stage_ decision variables, since the initial facilities^[Data centers, HPC centers, networks. ] are fixed and $y\in\mathbb{R}^{\left|\mathscr{A}\right|\times\left|\mathscr{K}\right|}$ as the _second-stage_ decision variables, since the job-flow operating conditions are uncertain over time.

The two-stage stochastic linear program [@birgelouveaux2011], [@shapiro_lectures_2009] is then

$$\begin{align} \label{eq:2stage}
\min_{x\in\mathscr{X}} & \,\,c^{\top}x + \mathrm{E}\left[Q(x;\xi)\right],
\end{align}$$
where $Q(x;\xi)$ is the optimal value of the second-stage problem
$$\begin{align*}
\min_{y\ge0} & \,\,q^{\top}y\\
\textrm{s.t.} & \,\,Ny=0,\\
 & Cy\ge d,\\
 & Sy\le s,\\
 & Ry\le Mx,
\end{align*}$$
where $d$ is the (uncertain) resource demand, $s$ is the (uncertain) resource supply, the random vector $\xi=(q,d,s,R,M)$ and $y=y(\xi).$ The expectation is taken with respect to the joint probability distribution function^[Either continuous or discrete, it is derived either from theory or observations, or both.] of $\xi.$  In the terminology of state-space, we can consider $x$ as the _state_ variable, and $y$  as the _control_ variable.

To treat the occurrence of infeasibility, where the first-stage solution
does not satisfy the second-stage constraints, e.g. $Cy\nleqslant d,$
we  introduce a _recourse_ action $z$  that supplies
the deficit $d-Cy$ at some penalty cost. Then the second-stage problem becomes
$$\begin{align*}
\min_{y\ge0} & \,\,q^{\top}y+h^{\top}z\\
\textrm{s.t.} & \,\,Ny=0,\\
 & Cy+z\ge d,\\
 & Sy\le s,\\
 & Ry\le Mx,
\end{align*}$$
where $h$ represents the vector of (positive) recourse costs.



In the multistage case, we will have a succession of recourse stages, yielding the multistage program [@powell2022], 

$$
    \min_{\pi \in \Pi} \mathrm{E} \left[ \sum^{T}_{t=1} \gamma^{t-1} f_t(x_t;\xi_t) \right],
$$
subject to
$$
     x_t \in \mathcal{X}_t(x_{t-1};\xi_{t-1}), \quad t=1 \ldots, T,
$$
where $\pi$ is a policy, $\gamma$ is a discount factor, $f_t$  is a cost function, $x_t$ is a decision and $\mathcal{X}_t$ are the constraints. A policy is, by definition, a method that optimizes the objective. For example, in Google maps, the policy is to decide whether to turn left or right by optimizing over the time required to transverse the next link in the network plus the remaining time to get to the destination.


Note that there are various forms of minimization in stochastic scheduling.  Whenever an objective function has to be minimized, it has to be specified in what sense the objective has to be minimized. 

- _Expectation_ sense is the crudest form of optimization,
e.g., one wishes to minimize (a function of) the expected makespan,
that is $\mathrm{E}\left[f\left(C_{\mathrm{max}}\right)\right],$
and find a policy under which the expected makespan is smaller than
the expected makespan under any other policy. 
- _Stochastic_ sense is a stronger form of optimization.
If a schedule or policy minimizes $f\left(C_{\mathrm{max}}\right)$
stochastically, then the makespan under the optimal schedule or policy
is stochastically (in probability, or in law) less than the makespan under any other schedule
or policy. 


## Value at Risk

TBC